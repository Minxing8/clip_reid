{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessing small scale\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from dataclasses import dataclass, field\n",
    "import random\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    n_folds: int = 10\n",
    "    data_dir: str = \"/home/minxing/datasets/NSVA_157_zeroshot_crops_new/player_crops\"\n",
    "    save_dir: str = \"./data/nsva\"\n",
    "    selected_game_endings: Optional[list] = field(default_factory=lambda: ['00160', '00060', '01212', '01055'])\n",
    "    challenge_game_ending: Optional[str] = '00151'  # Game ID ending for challenge\n",
    "    seed: int = 2024  # Seed for reproducibility\n",
    "    min_samples_per_player: int = 20  # Minimum number of crops per player\n",
    "    max_samples_per_player: int = 50  # Maximum number of crops per player\n",
    "    num_queries_per_player: int = 5   # Number of query images per player in the test set\n",
    "    num_test_players: int = 20        # Number of players in the test set\n",
    "    num_challenge_images_per_player: int = 5  # Number of images per player in challenge\n",
    "\n",
    "# Initialize configuration\n",
    "config = Configuration(\n",
    "    selected_game_endings=None,  # or [] to indicate no filtering\n",
    "    challenge_game_ending=None   # to skip challenge DataFrame creation\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Function to build the DataFrame with constraints on samples per player                                                #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "def build_dataframe(base_path, selected_game_endings):\n",
    "    img_id = []\n",
    "    folder = []\n",
    "    player = []\n",
    "    game = []\n",
    "    img_type = []\n",
    "    split = []\n",
    "    \n",
    "    # Iterate through each game_play directory\n",
    "    for game_play_dir in os.listdir(base_path):\n",
    "        game_play_path = os.path.join(base_path, game_play_dir)\n",
    "        \n",
    "        if os.path.isdir(game_play_path):\n",
    "            # Extract game_id from the directory name\n",
    "            if '-' not in game_play_dir:\n",
    "                print(f\"Skipping directory '{game_play_dir}' as it does not contain a hyphen '-'.\")\n",
    "                continue  # Skip directories that don't follow the 'game_id-play_id' format\n",
    "            \n",
    "            game_id_full = game_play_dir.split('-')[0]\n",
    "            game_id = game_id_full  # Use the full game_id\n",
    "            \n",
    "            # Check if game_id ends with one of the selected endings (if provided)\n",
    "            if selected_game_endings:\n",
    "                if not any(game_id.endswith(ending) for ending in selected_game_endings):\n",
    "                    continue  # Skip games not in the selected list\n",
    "            \n",
    "            # Debugging: Print matched game_play_dir\n",
    "            # print(f\"Matched game_play_dir: '{game_play_dir}' with game_id: '{game_id}'\")\n",
    "            \n",
    "            # Iterate through player directories inside each game-play directory\n",
    "            for player_id in os.listdir(game_play_path):\n",
    "                # Skip player directories with player_id == '0'\n",
    "                if player_id == '0':\n",
    "                    # print(f\"Skipping player directory '0' in game '{game_id}'.\")\n",
    "                    continue\n",
    "                \n",
    "                player_dir_path = os.path.join(game_play_path, player_id)\n",
    "                \n",
    "                if os.path.isdir(player_dir_path):\n",
    "                    # Get all image files in the player directory\n",
    "                    image_files = [f for f in os.listdir(player_dir_path) if os.path.isfile(os.path.join(player_dir_path, f))]\n",
    "                    \n",
    "                    # Ensure minimum number of samples per player\n",
    "                    if len(image_files) < config.min_samples_per_player:\n",
    "                        print(f\"Skipping player '{player_id}' in game '{game_id}' due to insufficient images ({len(image_files)}).\")\n",
    "                        continue  # Skip players with less than min_samples_per_player\n",
    "                    \n",
    "                    # Randomly shuffle the image files to ensure randomness\n",
    "                    random.shuffle(image_files)\n",
    "                    \n",
    "                    # Limit to max_samples_per_player\n",
    "                    if len(image_files) > config.max_samples_per_player:\n",
    "                        image_files = image_files[:config.max_samples_per_player]\n",
    "                        # print(f\"Limiting player '{player_id}' in game '{game_id}' to {config.max_samples_per_player} images.\")\n",
    "                    \n",
    "                    # Iterate through image files\n",
    "                    for image_file in image_files:\n",
    "                        image_path = os.path.join(player_dir_path, image_file)\n",
    "                        if os.path.isfile(image_path):\n",
    "                            # Extract image information\n",
    "                            img_id.append(os.path.splitext(image_file)[0])  # Remove file extension\n",
    "                            folder.append(player_dir_path)  # Full path to the player's directory\n",
    "                            player.append(player_id)\n",
    "                            game.append(game_id)\n",
    "                            split.append('all')  # Will update later\n",
    "                            img_type.append('g')  # Default to 'g'; will adjust later\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"img_id\": img_id,\n",
    "        \"folder\": folder,  # Full path to the player's directory\n",
    "        \"player\": player,\n",
    "        \"game\": game,\n",
    "        \"split\": split,\n",
    "        \"img_type\": img_type,\n",
    "    })\n",
    "\n",
    "    # print(f\"Total images collected from selected games: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Build DataFrame for Selected Games or All Games if No Selection                                                         #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Pass selected_game_endings only if it's provided\n",
    "df_train = build_dataframe(os.path.join(config.data_dir, 'train'), config.selected_game_endings)\n",
    "df_test = build_dataframe(os.path.join(config.data_dir, 'test'), config.selected_game_endings)\n",
    "\n",
    "# Combine the dataframes\n",
    "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(f\"Combined DataFrame contains {len(df_full)} images.\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Assign Splits and Img Types                                                                                           #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Get unique player IDs\n",
    "unique_players = df_full['player'].unique()\n",
    "print(f\"Total unique players before splitting: {len(unique_players)}\")\n",
    "\n",
    "# Randomly select players for the test split\n",
    "num_test_players = min(config.num_test_players, len(unique_players))\n",
    "test_players = np.random.choice(unique_players, size=num_test_players, replace=False)\n",
    "print(f\"Selected {len(test_players)} players for the test split.\")\n",
    "\n",
    "# Update the 'split' column based on player IDs\n",
    "df_full['split'] = df_full['player'].apply(lambda x: 'test' if x in test_players else 'train')\n",
    "\n",
    "# Now, for the test split, assign 'q' and 'g' in 'img_type' column\n",
    "df_full['img_type'] = df_full['img_type'].astype(str)  # Ensure it's of type str\n",
    "\n",
    "# For each player in the test set, select num_queries_per_player images as query and the rest as gallery\n",
    "for player_id in test_players:\n",
    "    player_df = df_full[(df_full['player'] == player_id) & (df_full['split'] == \"test\")]\n",
    "    if len(player_df) == 0:\n",
    "        continue  # Skip if no images for this player\n",
    "\n",
    "    # Check if player has enough images for queries\n",
    "    if len(player_df) <= config.num_queries_per_player:\n",
    "        print(f\"Player '{player_id}' has only {len(player_df)} images in test set, setting all as queries.\")\n",
    "        df_full.loc[player_df.index, 'img_type'] = 'q'\n",
    "    else:\n",
    "        # Randomly select num_queries_per_player images as query\n",
    "        query_idx = player_df.sample(n=config.num_queries_per_player, random_state=config.seed).index\n",
    "        df_full.loc[query_idx, 'img_type'] = 'q'\n",
    "\n",
    "        # The rest are gallery\n",
    "        gallery_idx = player_df.index.difference(query_idx)\n",
    "        df_full.loc[gallery_idx, 'img_type'] = 'g'\n",
    "\n",
    "# For the training set, set 'img_type' to 'g' (gallery)\n",
    "df_full.loc[df_full['split'] == 'train', 'img_type'] = 'g'\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Build Challenge DataFrame (Only if challenge_game_ending is provided)                                                #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "df_challenge = pd.DataFrame()  # Initialize empty DataFrame\n",
    "\n",
    "if config.challenge_game_ending:\n",
    "    def build_challenge_dataframe(base_paths, game_ending, num_images_per_player, seed=2024):\n",
    "        img_id = []\n",
    "        folder = []\n",
    "        player = []\n",
    "        game = []\n",
    "        img_type = []\n",
    "        split = []\n",
    "        \n",
    "        # Set seed for reproducibility\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        # Iterate through each base path ('train' and 'test')\n",
    "        for base_path in base_paths:\n",
    "            for game_play_dir in os.listdir(base_path):\n",
    "                game_play_path = os.path.join(base_path, game_play_dir)\n",
    "                \n",
    "                if not os.path.isdir(game_play_path):\n",
    "                    continue  # Skip if not a directory\n",
    "\n",
    "                # Extract game_id from directory name\n",
    "                if '-' not in game_play_dir:\n",
    "                    continue  # Skip directories without '-'\n",
    "                game_id_full = game_play_dir.split('-')[0]\n",
    "                game_id = game_id_full\n",
    "\n",
    "                # Check if game_id ends with the challenge ending\n",
    "                if not game_id.endswith(game_ending):\n",
    "                    continue  # Skip games not ending with the specified ending\n",
    "                \n",
    "                # Debugging: Print matched challenge game_play_dir\n",
    "                # print(f\"Matched challenge game_play_dir: '{game_play_dir}' with game_id: '{game_id}'\")\n",
    "                \n",
    "                # Iterate through player directories inside each game-play directory\n",
    "                for player_id in os.listdir(game_play_path):\n",
    "                    # Skip player directories with player_id == '0'\n",
    "                    if player_id == '0':\n",
    "                        # print(f\"Skipping player directory '0' in challenge game '{game_id}'.\")\n",
    "                        continue\n",
    "                    \n",
    "                    player_dir_path = os.path.join(game_play_path, player_id)\n",
    "                    \n",
    "                    if os.path.isdir(player_dir_path):\n",
    "                        # Get all image files in the player directory\n",
    "                        image_files = [f for f in os.listdir(player_dir_path) if os.path.isfile(os.path.join(player_dir_path, f))]\n",
    "                        \n",
    "                        # Ensure minimum number of samples per player\n",
    "                        if len(image_files) < num_images_per_player:\n",
    "                            print(f\"Skipping player '{player_id}' in challenge game '{game_id}' due to insufficient images ({len(image_files)}).\")\n",
    "                            continue  # Skip players with less than required images\n",
    "                        \n",
    "                        # Randomly shuffle the image files to ensure randomness\n",
    "                        random.shuffle(image_files)\n",
    "                        \n",
    "                        # Limit to num_images_per_player\n",
    "                        if len(image_files) > num_images_per_player:\n",
    "                            image_files = image_files[:num_images_per_player]\n",
    "                            # Alternatively, if you want to always select exactly num_images_per_player:\n",
    "                            # image_files = np.random.choice(image_files, size=num_images_per_player, replace=False).tolist()\n",
    "                        \n",
    "                        # Iterate through selected image files\n",
    "                        for image_file in image_files:\n",
    "                            image_path = os.path.join(player_dir_path, image_file)\n",
    "                            if os.path.isfile(image_path):\n",
    "                                # Extract image information\n",
    "                                img_id.append(os.path.splitext(image_file)[0])  # Remove file extension\n",
    "                                folder.append(player_dir_path)  # Full path to the player's directory\n",
    "                                player.append(player_id)\n",
    "                                game.append(game_id)\n",
    "                                split.append('challenge')\n",
    "                                img_type.append('g')  # Default to 'g'; will adjust later\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"img_id\": img_id,\n",
    "            \"folder\": folder,  # Full path to the player's directory\n",
    "            \"player\": player,\n",
    "            \"game\": game,\n",
    "            \"split\": split,\n",
    "            \"img_type\": img_type,\n",
    "        })\n",
    "\n",
    "        print(f\"Total challenge images collected: {len(df)}\")\n",
    "        return df\n",
    "    \n",
    "    # Build Challenge DataFrame\n",
    "    # Search both 'train' and 'test' directories for games ending with the challenge_game_ending\n",
    "    base_paths_for_challenge = [os.path.join(config.data_dir, 'train'), os.path.join(config.data_dir, 'test')]\n",
    "    df_challenge = build_challenge_dataframe(\n",
    "        base_paths=base_paths_for_challenge,\n",
    "        game_ending=config.challenge_game_ending,\n",
    "        num_images_per_player=config.num_challenge_images_per_player,\n",
    "        seed=config.seed\n",
    "    )\n",
    "    \n",
    "    # Check if challenge_df is empty\n",
    "    if df_challenge.empty:\n",
    "        print(\"No challenge images found. Please check if game_play directories ending with \"\n",
    "              f\"'{config.challenge_game_ending}' exist in 'train' or 'test' directories.\")\n",
    "    else:\n",
    "        #----------------------------------------------------------------------------------------------------------------------#\n",
    "        # Assign Query and Gallery Types for Challenge                                                                        #\n",
    "        #----------------------------------------------------------------------------------------------------------------------#\n",
    "        # Get unique players in challenge\n",
    "        challenge_players = df_challenge['player'].unique()\n",
    "        num_players = len(challenge_players)\n",
    "        print(f\"Total unique players in challenge set: {num_players}\")\n",
    "        \n",
    "        if num_players == 0:\n",
    "            print(\"No challenge players to assign 'q' and 'g' types.\")\n",
    "        else:\n",
    "            # Determine number of players in query and gallery to balance\n",
    "            num_query_players = num_players // 2\n",
    "            num_gallery_players = num_players - num_query_players\n",
    "            \n",
    "            # Shuffle players\n",
    "            shuffled_players = list(challenge_players)\n",
    "            random.shuffle(shuffled_players)\n",
    "            \n",
    "            # Assign players to query and gallery\n",
    "            query_players = set(shuffled_players[:num_query_players])\n",
    "            gallery_players = set(shuffled_players[num_query_players:])\n",
    "            \n",
    "            print(f\"Assigning {len(query_players)} players to query and {len(gallery_players)} players to gallery in the challenge set.\")\n",
    "            \n",
    "            # Assign img_type based on player assignment\n",
    "            df_challenge['img_type'] = df_challenge['player'].apply(lambda x: 'q' if x in query_players else 'g')\n",
    "else:\n",
    "    print(\"No challenge_game_ending provided. Skipping challenge DataFrame creation.\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Map player IDs to integer labels starting from 0                                                                      #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Map train and test players\n",
    "unique_players_full = df_full['player'].unique()\n",
    "player_id_map_full = {player_id: idx for idx, player_id in enumerate(unique_players_full)}\n",
    "df_full['player'] = df_full['player'].map(player_id_map_full).astype(int)\n",
    "\n",
    "if config.challenge_game_ending and not df_challenge.empty:\n",
    "    # Map challenge players to new unique IDs\n",
    "    # Find the max current player ID\n",
    "    max_player_id = df_full['player'].max()\n",
    "    challenge_unique_players = df_challenge['player'].unique()\n",
    "    challenge_player_id_map = {player_id: idx + max_player_id + 1 for idx, player_id in enumerate(challenge_unique_players)}\n",
    "    df_challenge['player'] = df_challenge['player'].map(challenge_player_id_map).astype(int)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Assign Folds for Cross-Validation                                                                                    #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "df_full['fold'] = -1\n",
    "\n",
    "# Assign folds only to training data\n",
    "df_train_full = df_full[df_full['split'] == 'train'].copy()\n",
    "\n",
    "n_splits = min(config.n_folds, df_train_full['player'].nunique())\n",
    "print(f\"Assigning folds using GroupKFold with {n_splits} splits.\")\n",
    "cv = GroupKFold(n_splits=n_splits)\n",
    "split = list(cv.split(df_train_full, groups=df_train_full['player']))\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(split):\n",
    "    df_train_full.loc[df_train_full.index[val_idx], \"fold\"] = i\n",
    "    # print(f\"Assigned fold {i} with {len(val_idx)} validation samples.\")\n",
    "\n",
    "# Update df_full with the fold information\n",
    "df_full.update(df_train_full)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Save DataFrames                                                                                                      #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Save the combined training and test DataFrame\n",
    "train_df_path_saved = os.path.join(config.save_dir, \"train_df.csv\")\n",
    "df_full.to_csv(train_df_path_saved, index=False)\n",
    "\n",
    "# Save the challenge DataFrame only if it exists\n",
    "if config.challenge_game_ending and not df_challenge.empty:\n",
    "    challenge_df_path_saved = os.path.join(config.save_dir, \"challenge_df.csv\")\n",
    "    df_challenge.to_csv(challenge_df_path_saved, index=False)\n",
    "    challenge_df_saved = True\n",
    "else:\n",
    "    challenge_df_saved = False\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nDataFrames saved:\")\n",
    "print(f\" - Training/Test DataFrame: {train_df_path_saved}\")\n",
    "if challenge_df_saved:\n",
    "    print(f\" - Challenge DataFrame: {challenge_df_path_saved}\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Number of total images: {len(df_full)}\")\n",
    "print(f\"Number of training images: {len(df_full[df_full['split'] == 'train'])}\")\n",
    "print(f\"Number of testing images: {len(df_full[df_full['split'] == 'test'])}\")\n",
    "print(f\"Number of unique training players: {df_full[df_full['split'] == 'train']['player'].nunique()}\")\n",
    "print(f\"Number of unique testing players: {df_full[df_full['split'] == 'test']['player'].nunique()}\")\n",
    "if challenge_df_saved:\n",
    "    print(f\"Number of challenge images: {len(df_challenge)}\")\n",
    "    print(f\"Number of unique challenge players: {df_challenge['player'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minxing/miniconda3/envs/clipreident/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/minxing/miniconda3/envs/clipreident/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: ('ViT-L-14', 'openai')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minxing/miniconda3/envs/clipreident/lib/python3.8/site-packages/open_clip/factory.py:372: UserWarning: These pretrained weights were trained with QuickGELU activation but the model config does not have that enabled. Consider using a model config with a \"-quickgelu\" suffix or enable with a flag.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove Projection Layer - old output size: 768 - new output size: 1024\n",
      "\n",
      "GPUs available: 2\n",
      "\n",
      "Image Size: (224, 224)\n",
      "Mean: (0.48145466, 0.4578275, 0.40821073)\n",
      "Std:  (0.26862954, 0.26130258, 0.27577711)\n",
      "\n",
      "Images train: 15193\n",
      "\n",
      "Shuffle Training Data:\n",
      "Length Train: 15193\n",
      "First Element: 000128_9\n",
      "\n",
      "Warmup Epochs: 1.0 - Warmup Steps: 949\n",
      "Train Epochs:  4 - Train Steps:  3796\n",
      "\n",
      "Scheduler: polynomial - max LR: 4e-05 - end LR: 1e-05\n",
      "\n",
      "----------------------------------[Zero-Shot]-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1973736/1448433461.py:392: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(init_scale=2.**10)\n",
      "Test : 100%|##########| 50/50 [00:34<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without re-ranking:\n",
      "mAP: 58.47%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         21.69%      57.87%      98.67%\n",
      "  top-5         30.02%      86.27%     100.00%\n",
      "  top-10        34.49%      94.93%     100.00%\n",
      "\n",
      "With re-ranking:\n",
      "mAP: 66.73%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         26.08%      66.53%     100.00%\n",
      "  top-5         40.27%      86.67%     100.00%\n",
      "  top-10        44.98%      94.80%     100.00%\n",
      "\n",
      "-----------------------------------[Epoch: 1]-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|##########| 949/949 [06:33<00:00,  2.41it/s, loss=2.82, lr=0.000040]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Train Loss = 2.3967 - Lr = 0.000040\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test : 100%|##########| 50/50 [00:41<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without re-ranking:\n",
      "mAP: 62.92%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         24.49%      58.40%     100.00%\n",
      "  top-5         32.29%      88.67%     100.00%\n",
      "  top-10        36.73%      97.60%     100.00%\n",
      "\n",
      "With re-ranking:\n",
      "mAP: 72.20%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         29.21%      69.20%      98.67%\n",
      "  top-5         46.26%      90.00%      98.67%\n",
      "  top-10        51.39%      96.80%     100.00%\n",
      "\n",
      "Shuffle Training Data:\n",
      "Length Train: 15193\n",
      "First Element: 000417_7\n",
      "\n",
      "-----------------------------------[Epoch: 2]-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|##########| 949/949 [06:41<00:00,  2.36it/s, loss=2.78, lr=0.000023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Train Loss = 1.9904 - Lr = 0.000023\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test : 100%|##########| 50/50 [00:41<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without re-ranking:\n",
      "mAP: 49.60%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         19.21%      48.40%     100.00%\n",
      "  top-5         25.61%      78.80%     100.00%\n",
      "  top-10        28.58%      92.53%     100.00%\n",
      "\n",
      "With re-ranking:\n",
      "mAP: 61.77%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         24.82%      59.20%     100.00%\n",
      "  top-5         38.62%      82.67%     100.00%\n",
      "  top-10        43.92%      94.27%     100.00%\n",
      "\n",
      "Shuffle Training Data:\n",
      "Length Train: 15193\n",
      "First Element: 000119_7\n",
      "\n",
      "-----------------------------------[Epoch: 3]-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|##########| 949/949 [06:42<00:00,  2.36it/s, loss=2.52, lr=0.000013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Train Loss = 1.7472 - Lr = 0.000013\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test : 100%|##########| 50/50 [00:42<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without re-ranking:\n",
      "mAP: 62.46%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         27.22%      58.13%     100.00%\n",
      "  top-5         35.38%      90.13%     100.00%\n",
      "  top-10        39.47%      95.73%     100.00%\n",
      "\n",
      "With re-ranking:\n",
      "mAP: 73.25%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         32.06%      70.40%      98.67%\n",
      "  top-5         51.84%      91.60%      98.67%\n",
      "  top-10        56.28%      97.47%      98.67%\n",
      "\n",
      "Shuffle Training Data:\n",
      "Length Train: 15193\n",
      "First Element: 000358_11\n",
      "\n",
      "-----------------------------------[Epoch: 4]-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|##########| 949/949 [06:43<00:00,  2.35it/s, loss=2.54, lr=0.000010]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. Train Loss = 1.5876 - Lr = 0.000010\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test : 100%|##########| 50/50 [00:41<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Without re-ranking:\n",
      "mAP: 54.67%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         22.29%      53.07%      98.67%\n",
      "  top-5         29.52%      80.93%     100.00%\n",
      "  top-10        33.35%      93.33%     100.00%\n",
      "\n",
      "With re-ranking:\n",
      "mAP: 65.73%\n",
      "CMC Scores    allshots      cuhk03  market1501\n",
      "  top-1         29.58%      61.07%     100.00%\n",
      "  top-5         45.14%      82.13%     100.00%\n",
      "  top-10        50.51%      94.27%     100.00%\n",
      "\n",
      "Shuffle Training Data:\n",
      "Length Train: 15193\n",
      "First Element: 000118_9\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader  \n",
    "\n",
    "# Import custom modules\n",
    "from clipreid.loss import ClipLoss\n",
    "from clipreid.trainer import train, get_scheduler\n",
    "from clipreid.utils import Logger, setup_system, print_line\n",
    "from clipreid.model import TimmModel, OpenClipModel\n",
    "from clipreid.transforms import get_transforms\n",
    "from clipreid.evaluator import predict, compute_dist_matrix, compute_scores\n",
    "\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    # Model configurations\n",
    "    model: str = ('ViT-L-14', 'openai')\n",
    "    remove_proj = True\n",
    "    img_size: int = (224, 224)\n",
    "    mean:   float = (0.485, 0.456, 0.406)\n",
    "    std:    float = (0.229, 0.224, 0.225)\n",
    "    \n",
    "    # Data settings\n",
    "    train_on_all: bool = False\n",
    "    fold: int = -1  # Use -1 to specify custom behavior\n",
    "    seed: int = 2024  # Updated seed for consistency\n",
    "    epochs: int = 4\n",
    "    batch_size: int = 16\n",
    "    batch_size_eval: int = 64\n",
    "    gpu_ids: tuple = (0,)\n",
    "    mixed_precision: bool = True\n",
    "    lr: float = 0.00004\n",
    "    scheduler: str = \"polynomial\"\n",
    "    warmup_epochs: float = 1.0\n",
    "    lr_end: float = 0.00001\n",
    "    gradient_clipping: float = None\n",
    "    grad_checkpointing: bool = False\n",
    "    gradient_accumulation: int = 1\n",
    "    label_smoothing: float = 0.1\n",
    "    zero_shot: bool = True\n",
    "    rerank: bool = True\n",
    "    normalize_features: bool = True\n",
    "    data_dir: str = \"/home/minxing/datasets/NSVA_157_zeroshot_crops_new/player_crops\"\n",
    "    data_csv: str = \"./data/nsva/train_df.csv\"\n",
    "    prob_flip: float = 0.5\n",
    "    model_path: str = \"./model_nsva\"\n",
    "    checkpoint_start: str = None\n",
    "    verbose: bool = True \n",
    "    num_workers: int = 0 if os.name == 'nt' else 8  \n",
    "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu' \n",
    "    cudnn_benchmark: bool = True\n",
    "    cudnn_deterministic: bool = True      \n",
    "\n",
    "# Initialize configuration\n",
    "config = Configuration()\n",
    "\n",
    "# Ensure the model path exists\n",
    "if isinstance(config.model, tuple):\n",
    "    # Clip models\n",
    "    if config.train_on_all:\n",
    "        model_path = \"{}/{}_{}/all_data_seed_{}\".format(config.model_path,\n",
    "                                               config.model[0],\n",
    "                                               config.model[1],\n",
    "                                               config.seed)\n",
    "    else:\n",
    "        model_path = \"{}/{}_{}/fold{}_seed_{}\".format(config.model_path,\n",
    "                                               config.model[0],\n",
    "                                               config.model[1],\n",
    "                                               config.fold,\n",
    "                                               config.seed)\n",
    "else:\n",
    "    # Timm models\n",
    "    if config.train_on_all:\n",
    "        model_path = \"{}/{}/all_data_seed_{}\".format(config.model_path,\n",
    "                                                     config.model,\n",
    "                                                     config.seed)\n",
    "    else:\n",
    "        model_path = \"{}/{}/fold{}_seed_{}\".format(config.model_path,\n",
    "                                            config.model,\n",
    "                                            config.seed)\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# Redirect print to both console and log file\n",
    "sys.stdout = Logger(\"{}/log.txt\".format(model_path))\n",
    "\n",
    "# Set seed for reproducibility\n",
    "setup_system(seed=config.seed,\n",
    "             cudnn_benchmark=config.cudnn_benchmark,\n",
    "             cudnn_deterministic=config.cudnn_deterministic)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Model                                                                                                                #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "print(\"\\nModel: {}\".format(config.model))\n",
    "\n",
    "if isinstance(config.model, tuple):\n",
    "\n",
    "    model = OpenClipModel(config.model[0],\n",
    "                          config.model[1],\n",
    "                          remove_proj=config.remove_proj\n",
    "                          )\n",
    "    \n",
    "    img_size = model.get_image_size()\n",
    "    \n",
    "    mean=(0.48145466, 0.4578275, 0.40821073)\n",
    "    std=(0.26862954, 0.26130258, 0.27577711)\n",
    "    \n",
    "    if config.grad_checkpointing: \n",
    "        model.set_grad_checkpoint(enable=config.grad_checkpointing)\n",
    "       \n",
    "else:\n",
    "    model = TimmModel(config.model,\n",
    "                      pretrained=True)\n",
    "\n",
    "    img_size = config.img_size\n",
    "    mean = config.mean\n",
    "    std = config.std\n",
    "    \n",
    "# Load pretrained checkpoint if provided   \n",
    "if config.checkpoint_start is not None:  \n",
    "    print(\"\\nStart from:\", config.checkpoint_start)\n",
    "    model_state_dict = torch.load(config.checkpoint_start)  \n",
    "    model.load_state_dict(model_state_dict, strict=True)\n",
    "    \n",
    "# Data parallel\n",
    "print(\"\\nGPUs available:\", torch.cuda.device_count())  \n",
    "if torch.cuda.device_count() > 1 and len(config.gpu_ids) > 1:\n",
    "    print(\"Using Data Parallel with GPU IDs: {}\".format(config.gpu_ids))\n",
    "    model = torch.nn.DataParallel(model, device_ids=config.gpu_ids)    \n",
    "    multi_gpu = True\n",
    "else:\n",
    "    multi_gpu = False  \n",
    "    \n",
    "# Model to device   \n",
    "model = model.to(config.device)\n",
    "\n",
    "print(\"\\nImage Size:\", img_size)\n",
    "print(\"Mean: {}\".format(mean))\n",
    "print(\"Std:  {}\".format(std)) \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# DataLoader                                                                                                           #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Data\n",
    "df = pd.read_csv(config.data_csv)\n",
    "\n",
    "# Split data\n",
    "if config.train_on_all:\n",
    "    df_train = df[df['split'] == 'train']\n",
    "    df_test = df[df[\"split\"] == \"test\"]\n",
    "else:\n",
    "    if config.fold == -1:\n",
    "        # Use given test split\n",
    "        df_train = df[df[\"split\"] == \"train\"]\n",
    "        df_test = df[df[\"split\"] == \"test\"]\n",
    "    else:\n",
    "        # Use custom folds\n",
    "        df_train = df[df[\"fold\"] != config.fold]\n",
    "        df_test = df[df[\"fold\"] == config.fold]\n",
    "\n",
    "# Transforms\n",
    "val_transforms, train_transforms = get_transforms(img_size, mean, std)\n",
    "\n",
    "# Custom Dataset Classes\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import copy\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "class CustomTrainDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 image_transforms=None,\n",
    "                 prob_flip=0.5,\n",
    "                 shuffle_batch_size=16):\n",
    "        \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_transforms = image_transforms\n",
    "        self.prob_flip = prob_flip\n",
    "        self.shuffle_batch_size = shuffle_batch_size\n",
    "        \n",
    "        print(\"\\nImages train: {}\".format(len(self.df)))\n",
    "        self.images = self.df['img_id'].tolist()\n",
    "        \n",
    "        # Map img_id to index in dataframe for quick access\n",
    "        self.img_id_to_index = {img_id: idx for idx, img_id in enumerate(self.df['img_id'])}\n",
    "        \n",
    "        # dict for all images for a given player\n",
    "        self.player_images = defaultdict(list)\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_id = row['img_id']\n",
    "            player = row['player']\n",
    "            self.player_images[player].append(img_id)\n",
    "  \n",
    "        # dict for all gallery images for a given image\n",
    "        self.player_images_other = {}\n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_id = row['img_id']\n",
    "            player = row['player']\n",
    "            other_images = copy.deepcopy(self.player_images[player])\n",
    "            other_images.remove(img_id)\n",
    "            self.player_images_other[img_id] = np.array(other_images)\n",
    "\n",
    "        self.samples = copy.deepcopy(self.images)\n",
    "        self.shuffle()\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        # Query image\n",
    "        img_id_query = self.samples[index]\n",
    "        record_query = self.df.loc[self.img_id_to_index[img_id_query]]\n",
    "        img_path_query = os.path.join(record_query['folder'], img_id_query + '.jpg')\n",
    "        \n",
    "        img_query = cv2.imread(img_path_query)\n",
    "        img_query = cv2.cvtColor(img_query, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.image_transforms:\n",
    "            img_query = self.image_transforms(image=img_query)['image']\n",
    "        \n",
    "        # Randomly select one other image of the same player as gallery image\n",
    "        if len(self.player_images_other[img_id_query]) > 0:\n",
    "            img_id_gallery = np.random.choice(self.player_images_other[img_id_query], 1)[0]\n",
    "        else:\n",
    "            img_id_gallery = img_id_query  # If no other images, use the same image\n",
    "        record_gallery = self.df.loc[self.img_id_to_index[img_id_gallery]]\n",
    "        img_path_gallery = os.path.join(record_gallery['folder'], img_id_gallery + '.jpg')\n",
    "    \n",
    "        img_gallery = cv2.imread(img_path_gallery)\n",
    "        img_gallery = cv2.cvtColor(img_gallery, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.image_transforms:\n",
    "            img_gallery = self.image_transforms(image=img_gallery)['image']\n",
    "  \n",
    "        # Player ID as label\n",
    "        player = torch.tensor(int(record_query['player']), dtype=torch.long)\n",
    "        \n",
    "        # Random flip both images\n",
    "        if np.random.random() < self.prob_flip:\n",
    "            img_query = transforms.functional.hflip(img_query)\n",
    "            img_gallery = transforms.functional.hflip(img_gallery)\n",
    "        \n",
    "        return img_query, img_gallery, player\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def shuffle(self):\n",
    "        '''\n",
    "        Custom shuffle function to prevent having the same player twice in the same batch.\n",
    "        '''\n",
    "        \n",
    "        img_ids_select = copy.deepcopy(self.images)\n",
    "        random.shuffle(img_ids_select)\n",
    "\n",
    "        batches = []\n",
    "        players_batch = set()\n",
    "        batch = []\n",
    "        break_counter = 0\n",
    "        \n",
    "        while img_ids_select:\n",
    "            img_id = img_ids_select.pop(0)\n",
    "            player = self.df.loc[self.img_id_to_index[img_id]]['player']\n",
    "            \n",
    "            if player not in players_batch:\n",
    "                players_batch.add(player)\n",
    "                batch.append(img_id)\n",
    "                \n",
    "                # If batch is filled, reset\n",
    "                if len(batch) == self.shuffle_batch_size:\n",
    "                    batches.extend(batch)\n",
    "                    batch = []\n",
    "                    players_batch = set()\n",
    "                    break_counter = 0\n",
    "            else:\n",
    "                # Append at the end for later consideration\n",
    "                img_ids_select.append(img_id)\n",
    "                break_counter += 1\n",
    "                \n",
    "                if break_counter >= len(img_ids_select):\n",
    "                    # Can't fill batch without repeating players, so we accept duplicates\n",
    "                    batches.extend(batch)\n",
    "                    batch = []\n",
    "                    players_batch = set()\n",
    "                    break_counter = 0\n",
    "        \n",
    "        # Add any remaining images\n",
    "        if batch:\n",
    "            batches.extend(batch)\n",
    "        \n",
    "        self.samples = batches\n",
    "        print(\"\\nShuffle Training Data:\")\n",
    "        print(\"Length Train:\", len(self.samples))\n",
    "        if len(self.samples) > 0:\n",
    "            print(\"First Element: {}\".format(self.samples[0]))\n",
    "\n",
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 image_transforms=None):\n",
    "        \n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_transforms = image_transforms\n",
    "        self.images = self.df['img_id'].tolist()\n",
    "        \n",
    "        self.query = []\n",
    "        self.gallery = []\n",
    "        self.all = []\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            img_id = row['img_id']\n",
    "            player = int(row['player'])\n",
    "            img_type = row['img_type']\n",
    "            folder = row['folder']\n",
    "            img_path = os.path.join(folder, img_id + '.jpg')\n",
    "            self.all.append((img_path, player, -1))\n",
    "            \n",
    "            if img_type == \"q\":\n",
    "                self.query.append((img_path, player, 0))\n",
    "            else:\n",
    "                self.gallery.append((img_path, player, 1))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img_id = self.df.loc[index, 'img_id']\n",
    "        img_path = os.path.join(self.df.loc[index, 'folder'], img_id + '.jpg')\n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.image_transforms:\n",
    "            img = self.image_transforms(image=img)['image']\n",
    "             \n",
    "        player = int(self.df.loc[index]['player'])\n",
    "        \n",
    "        if self.df.loc[index][\"img_type\"] == \"q\":\n",
    "            img_type = 0\n",
    "        else:\n",
    "            img_type = 1\n",
    "            \n",
    "        return img, img_path, player, img_type\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "# Initialize the custom datasets\n",
    "train_dataset = CustomTrainDataset(df=df_train,\n",
    "                                   image_transforms=train_transforms,\n",
    "                                   prob_flip=config.prob_flip,\n",
    "                                   shuffle_batch_size=config.batch_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=config.batch_size,\n",
    "                          num_workers=config.num_workers,\n",
    "                          shuffle=False,\n",
    "                          pin_memory=True,\n",
    "                          drop_last=True)\n",
    "\n",
    "# Validation\n",
    "test_dataset = CustomTestDataset(df=df_test,\n",
    "                                 image_transforms=val_transforms)\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=config.batch_size_eval,\n",
    "                         num_workers=config.num_workers,\n",
    "                         shuffle=False,\n",
    "                         pin_memory=True)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Loss                                                                                                                 #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "loss_fn = torch.nn.CrossEntropyLoss(label_smoothing=config.label_smoothing)\n",
    "loss_function = ClipLoss(loss_function=loss_fn,\n",
    "                         device=config.device)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Optimizer and Scaler                                                                                                 #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
    "\n",
    "if config.mixed_precision:\n",
    "    scaler = torch.cuda.amp.GradScaler(init_scale=2.**10)\n",
    "else:\n",
    "    scaler = None\n",
    "    \n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Scheduler                                                                                                            #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "if config.scheduler is not None:\n",
    "    scheduler = get_scheduler(config,\n",
    "                              optimizer,\n",
    "                              train_loader_length=len(train_loader))       \n",
    "else:\n",
    "    scheduler = None\n",
    "   \n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Zero Shot                                                                                                            #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "if config.zero_shot:\n",
    "    \n",
    "    print_line(name=\"Zero-Shot\", length=80)\n",
    "    \n",
    "    features_dict = predict(model,\n",
    "                            dataloader=test_loader,\n",
    "                            device=config.device,\n",
    "                            normalize_features=config.normalize_features,\n",
    "                            verbose=config.verbose)\n",
    "    \n",
    "    dist_matrix, dist_matrix_rerank = compute_dist_matrix(features_dict, \n",
    "                                                          test_dataset.query,\n",
    "                                                          test_dataset.gallery,\n",
    "                                                          rerank=config.rerank)\n",
    "    \n",
    "    print(\"\\nWithout re-ranking:\")\n",
    "    mAP = compute_scores(dist_matrix,\n",
    "                         test_dataset.query,\n",
    "                         test_dataset.gallery)\n",
    "    \n",
    "    if dist_matrix_rerank is not None:\n",
    "        print(\"\\nWith re-ranking:\")\n",
    "        mAP = compute_scores(dist_matrix_rerank,\n",
    "                             test_dataset.query,\n",
    "                             test_dataset.gallery)\n",
    "        \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Train                                                                                                                #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "for epoch in range(1, config.epochs+1):\n",
    "\n",
    "    print_line(name=\"Epoch: {}\".format(epoch), length=80)\n",
    "    \n",
    "    # Train\n",
    "    train_loss = train(model,\n",
    "                       dataloader=train_loader,\n",
    "                       loss_function=loss_function,\n",
    "                       optimizer=optimizer,\n",
    "                       device=config.device,\n",
    "                       scheduler=scheduler,\n",
    "                       scaler=scaler,\n",
    "                       gradient_accumulation=config.gradient_accumulation,\n",
    "                       gradient_clipping=config.gradient_clipping,\n",
    "                       verbose=config.verbose,\n",
    "                       multi_gpu=multi_gpu)\n",
    "\n",
    "    print(\"Avg. Train Loss = {:.4f} - Lr = {:.6f}\\n\".format(train_loss,\n",
    "                                                           optimizer.param_groups[0]['lr']))\n",
    "    # Evaluate\n",
    "    features_dict = predict(model,\n",
    "                            dataloader=test_loader,\n",
    "                            device=config.device,\n",
    "                            normalize_features=config.normalize_features,\n",
    "                            verbose=config.verbose)\n",
    "    \n",
    "    dist_matrix, dist_matrix_rerank = compute_dist_matrix(features_dict, \n",
    "                                                          test_dataset.query,\n",
    "                                                          test_dataset.gallery,\n",
    "                                                          rerank=config.rerank)\n",
    "    \n",
    "    print(\"\\nWithout re-ranking:\")\n",
    "    mAP = compute_scores(dist_matrix,\n",
    "                         test_dataset.query,\n",
    "                         test_dataset.gallery)\n",
    "    \n",
    "    if dist_matrix_rerank is not None:\n",
    "        print(\"\\nWith re-ranking:\")\n",
    "        mAP_rerank = compute_scores(dist_matrix_rerank,\n",
    "                                    test_dataset.query,\n",
    "                                    test_dataset.gallery)\n",
    "        \n",
    "    checkpoint_path = '{}/weights_e{}.pth'.format(model_path, epoch)\n",
    "            \n",
    "    # Save model  \n",
    "    if torch.cuda.device_count() > 1 and len(config.gpu_ids) > 1:\n",
    "        torch.save(model.module.state_dict(), checkpoint_path)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    # Shuffle data for next epoch\n",
    "    train_loader.dataset.shuffle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from clipreid.model import TimmModel, OpenClipModel\n",
    "from clipreid.transforms import get_transforms\n",
    "from clipreid.dataset import TestDataset, ChallengeDataset\n",
    "from clipreid.evaluator import predict, compute_dist_matrix, compute_scores, write_mat_csv\n",
    "from clipreid.utils import print_line\n",
    "\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    '''\n",
    "    --------------------------------------------------------------------------\n",
    "    Open Clip Models:\n",
    "    --------------------------------------------------------------------------    \n",
    "    - ('RN50', 'openai')\n",
    "    - ('RN50', 'yfcc15m')\n",
    "    - ('RN50', 'cc12m')\n",
    "    - ('RN50-quickgelu', 'openai')\n",
    "    - ('RN50-quickgelu', 'yfcc15m')\n",
    "    - ('RN50-quickgelu', 'cc12m')\n",
    "    - ('RN101', 'openai')\n",
    "    - ('RN101', 'yfcc15m')\n",
    "    - ('RN101-quickgelu', 'openai')\n",
    "    - ('RN101-quickgelu', 'yfcc15m')\n",
    "    - ('RN50x4', 'openai')\n",
    "    - ('RN50x16', 'openai')\n",
    "    - ('RN50x64', 'openai')\n",
    "    - ('ViT-B-32', 'openai')\n",
    "    - ('ViT-B-32', 'laion2b_e16')\n",
    "    - ('ViT-B-32', 'laion400m_e31')\n",
    "    - ('ViT-B-32', 'laion400m_e32')\n",
    "    - ('ViT-B-32-quickgelu', 'openai')\n",
    "    - ('ViT-B-32-quickgelu', 'laion400m_e31')\n",
    "    - ('ViT-B-32-quickgelu', 'laion400m_e32')\n",
    "    - ('ViT-B-16', 'openai')\n",
    "    - ('ViT-B-16', 'laion400m_e31')\n",
    "    - ('ViT-B-16', 'laion400m_e32')\n",
    "    - ('ViT-B-16-plus-240', 'laion400m_e31')\n",
    "    - ('ViT-B-16-plus-240', 'laion400m_e32')\n",
    "    - ('ViT-L-14', 'openai')\n",
    "    - ('ViT-L-14', 'laion400m_e31')\n",
    "    - ('ViT-L-14', 'laion400m_e32')\n",
    "    - ('ViT-L-14-336', 'openai')\n",
    "    - ('ViT-H-14', 'laion2b_s32b_b79k')\n",
    "    - ('ViT-g-14', 'laion2b_s12b_b42k')\n",
    "    --------------------------------------------------------------------------\n",
    "    Timm Models:\n",
    "    --------------------------------------------------------------------------\n",
    "    - 'convnext_base_in22ft1k'\n",
    "    - 'convnext_large_in22ft1k'\n",
    "    - 'vit_base_patch16_224'\n",
    "    - 'vit_large_patch16_224'\n",
    "    - ...\n",
    "    - https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv\n",
    "    --------------------------------------------------------------------------\n",
    "    '''\n",
    "\n",
    "    # Model\n",
    "    model: tuple = ('ViT-L-14', 'openai')   # ('name of Clip model', 'name of dataset') | 'name of Timm model'\n",
    "    remove_proj: bool = True                # Remove projection for Clip ViT models\n",
    "\n",
    "    # Settings only for Timm models\n",
    "    img_size: tuple = (224, 224)             # Image size for Timm models\n",
    "    mean: tuple = (0.485, 0.456, 0.406)     # Mean of ImageNet\n",
    "    std: tuple = (0.229, 0.224, 0.225)      # Std of ImageNet\n",
    "\n",
    "    # Eval\n",
    "    batch_size: int = 64                    # Batch size for evaluation\n",
    "    normalize_features: bool = True         # L2 normalize features during eval  \n",
    "\n",
    "    # Split for Eval\n",
    "    fold: int = -1                          # -1 for given test split | int >=0 for custom folds \n",
    "\n",
    "    # Checkpoints: tuple of str for ensemble (checkpoint1, checkpoint2, ...)\n",
    "    checkpoints: tuple = (\n",
    "        \"./model_nsva/ViT-L-14_openai/fold0_seed_2024/weights_e4.pth\",\n",
    "        \"./model_nsva/ViT-L-14_openai/fold1_seed_2024/weights_e4.pth\"\n",
    "    )\n",
    "\n",
    "    # Dataset\n",
    "    data_dir: str = \"./data/nsva\"\n",
    "    challenge_csv: str = \"./data/nsva/challenge_df.csv\"\n",
    "\n",
    "    # Show progress bar\n",
    "    verbose: bool = True \n",
    "\n",
    "    # Set num_workers to 0 if OS is Windows\n",
    "    num_workers: int = 0 if os.name == 'nt' else 8  \n",
    "\n",
    "    # Use GPU if available\n",
    "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "# Initialize configuration\n",
    "config = Configuration()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Model                                                                                                                #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "\n",
    "print(\"\\nModel: {}\".format(config.model))\n",
    "\n",
    "if isinstance(config.model, tuple):\n",
    "    model = OpenClipModel(config.model[0],\n",
    "                          config.model[1],\n",
    "                          remove_proj=config.remove_proj)\n",
    "    \n",
    "    img_size = model.get_image_size()\n",
    "    \n",
    "    mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "    std = (0.26862954, 0.26130258, 0.27577711)\n",
    "else:\n",
    "    model = TimmModel(config.model,\n",
    "                      pretrained=True)\n",
    "\n",
    "    img_size = config.img_size\n",
    "    mean = config.mean\n",
    "    std = config.std\n",
    "\n",
    "\n",
    "dist_matrix_list = []\n",
    "dist_matrix_rerank_list = []\n",
    "\n",
    "# Ensure checkpoints is a list\n",
    "if not isinstance(config.checkpoints, (list, tuple)):\n",
    "    checkpoints = [config.checkpoints]\n",
    "else:\n",
    "    checkpoints = config.checkpoints\n",
    "\n",
    "for checkpoint in checkpoints: \n",
    "\n",
    "    print_line(name=checkpoint, length=80)\n",
    "        \n",
    "    # Load pretrained Checkpoint     \n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(f\"Checkpoint '{checkpoint}' does not exist. Skipping.\")\n",
    "        continue\n",
    "    model_state_dict = torch.load(checkpoint, map_location=config.device)\n",
    "    model.load_state_dict(model_state_dict, strict=True)    \n",
    "      \n",
    "    # Model to device   \n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    print(\"\\nImage Size:\", img_size)\n",
    "    print(\"Mean: {}\".format(mean))\n",
    "    print(\"Std:  {}\".format(std)) \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # DataLoader                                                                                                       #\n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    \n",
    "    # Transforms\n",
    "    val_transforms, _ = get_transforms(img_size, mean, std)\n",
    "    \n",
    "    # Dataframes\n",
    "    train_df_path = os.path.join(config.data_dir, \"train_df.csv\")\n",
    "    challenge_df_path = config.challenge_csv\n",
    "    \n",
    "    if not os.path.exists(train_df_path):\n",
    "        print(f\"Training DataFrame not found at {train_df_path}\")\n",
    "        exit(1)\n",
    "    if not os.path.exists(challenge_df_path):\n",
    "        print(f\"Challenge DataFrame not found at {challenge_df_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    df_train = pd.read_csv(train_df_path)\n",
    "    df_challenge = pd.read_csv(challenge_df_path)\n",
    "     \n",
    "    if config.fold == -1:\n",
    "        # Use given test split\n",
    "        df_test = df_train[df_train[\"split\"] == \"test\"]\n",
    "    else:\n",
    "        # Use custom folds\n",
    "        df_test = df_train[df_train[\"fold\"] == config.fold]\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # Validation and Challenge                                                                                         #\n",
    "    #------------------------------------------------------------------------------------------------------------------#\n",
    "    test_dataset = TestDataset(img_path=config.data_dir,\n",
    "                               df=df_test,\n",
    "                               image_transforms=val_transforms)\n",
    "\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=config.batch_size,\n",
    "                             num_workers=config.num_workers,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)\n",
    "\n",
    "    # Challenge\n",
    "    challenge_dataset = ChallengeDataset(df=df_challenge,\n",
    "                                         image_transforms=val_transforms)\n",
    "\n",
    "    challenge_loader = DataLoader(challenge_dataset,\n",
    "                                  batch_size=config.batch_size,\n",
    "                                  num_workers=config.num_workers,\n",
    "                                  shuffle=False,\n",
    "                                  pin_memory=True)\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # Test                                                                                                             #\n",
    "    #------------------------------------------------------------------------------------------------------------------# \n",
    "    print_line(name=\"Eval Fold: {}\".format(config.fold), length=80)\n",
    "    \n",
    "    # Extract features for test set\n",
    "    features_dict = predict(model,\n",
    "                            dataloader=test_loader,\n",
    "                            device=config.device,\n",
    "                            normalize_features=config.normalize_features,\n",
    "                            verbose=config.verbose)\n",
    "    \n",
    "    # Compute distance matrix for test set\n",
    "    dist_matrix_test, dist_matrix_test_rerank = compute_dist_matrix(features_dict, \n",
    "                                                                    test_dataset.query,\n",
    "                                                                    test_dataset.gallery,\n",
    "                                                                    rerank=True)\n",
    "    \n",
    "    # Without re-ranking\n",
    "    print(\"\\nWithout re-ranking:\")\n",
    "    mAP_test = compute_scores(dist_matrix_test,\n",
    "                         test_dataset.query,\n",
    "                         test_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Test mAP: {mAP_test['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix without re-ranking\n",
    "    save_path_test = os.path.join(os.path.dirname(checkpoint), \"test_dmat.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_test)\n",
    "    write_mat_csv(save_path_test,\n",
    "                  dist_matrix_test,\n",
    "                  test_dataset.query,\n",
    "                  test_dataset.gallery) \n",
    "    \n",
    "    # With re-ranking\n",
    "    print(\"\\nWith re-ranking:\")\n",
    "    mAP_test_rerank = compute_scores(dist_matrix_test_rerank,\n",
    "                         test_dataset.query,\n",
    "                         test_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Test mAP with re-ranking: {mAP_test_rerank['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix with re-ranking\n",
    "    save_path_test_rerank = os.path.join(os.path.dirname(checkpoint), \"test_dmat_rerank.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_test_rerank)\n",
    "    write_mat_csv(save_path_test_rerank,\n",
    "                  dist_matrix_test_rerank,\n",
    "                  test_dataset.query,\n",
    "                  test_dataset.gallery) \n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # Challenge                                                                                                        #\n",
    "    #------------------------------------------------------------------------------------------------------------------#\n",
    "    print_line(name=\"Challenge\", length=80)\n",
    "    \n",
    "    # Extract features for challenge set\n",
    "    features_dict_challenge = predict(model,\n",
    "                            dataloader=challenge_loader,\n",
    "                            device=config.device,\n",
    "                            normalize_features=config.normalize_features,\n",
    "                            verbose=config.verbose)\n",
    "    \n",
    "    # Compute distance matrix for challenge set\n",
    "    dist_matrix_challenge, dist_matrix_challenge_rerank = compute_dist_matrix(features_dict_challenge, \n",
    "                                                                                challenge_dataset.query,\n",
    "                                                                                challenge_dataset.gallery,\n",
    "                                                                                rerank=True)\n",
    "    \n",
    "    # Collect for ensemble\n",
    "    if not dist_matrix_challenge.size == 0:\n",
    "        dist_matrix_list.append(dist_matrix_challenge)\n",
    "    if dist_matrix_challenge_rerank.size != 0:\n",
    "        dist_matrix_rerank_list.append(dist_matrix_challenge_rerank)\n",
    "    \n",
    "    # Compute and print scores for challenge set without re-ranking\n",
    "    print(\"\\nChallenge Set without re-ranking:\")\n",
    "    mAP_challenge = compute_scores(dist_matrix_challenge,\n",
    "                         challenge_dataset.query,\n",
    "                         challenge_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Challenge mAP: {mAP_challenge['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix without re-ranking for challenge\n",
    "    save_path_challenge = os.path.join(os.path.dirname(checkpoint), \"challenge_dmat.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_challenge)\n",
    "    write_mat_csv(save_path_challenge,\n",
    "                  dist_matrix_challenge,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery) \n",
    "    \n",
    "    # Compute and print scores for challenge set with re-ranking\n",
    "    print(\"\\nChallenge Set with re-ranking:\")\n",
    "    mAP_challenge_rerank = compute_scores(dist_matrix_challenge_rerank,\n",
    "                         challenge_dataset.query,\n",
    "                         challenge_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Challenge mAP with re-ranking: {mAP_challenge_rerank['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix with re-ranking for challenge\n",
    "    save_path_challenge_rerank = os.path.join(os.path.dirname(checkpoint), \"challenge_dmat_rerank.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_challenge_rerank)\n",
    "    write_mat_csv(save_path_challenge_rerank,\n",
    "                  dist_matrix_challenge_rerank,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery)\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Ensemble                                                                                                             #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "if len(dist_matrix_list) > 1:\n",
    "    \n",
    "    print_line(name=\"Ensemble\", length=80)\n",
    "    \n",
    "    # Without re-ranking\n",
    "    dist_matrix_ensemble = np.stack(dist_matrix_list, axis=0).mean(0)\n",
    "    save_path_ensemble = os.path.join(os.path.dirname(config.checkpoints[0]), \"challenge_dmat_ensemble.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_ensemble)\n",
    "    write_mat_csv(save_path_ensemble,\n",
    "                  dist_matrix_ensemble,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery) \n",
    "    \n",
    "    # With re-ranking\n",
    "    dist_matrix_rerank_ensemble = np.stack(dist_matrix_rerank_list, axis=0).mean(0)\n",
    "    save_path_rerank_ensemble = os.path.join(os.path.dirname(config.checkpoints[0]), \"challenge_dmat_rerank_ensemble.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_rerank_ensemble)\n",
    "    write_mat_csv(save_path_rerank_ensemble,\n",
    "                  dist_matrix_rerank_ensemble,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from clipreid.model import TimmModel, OpenClipModel\n",
    "from clipreid.transforms import get_transforms\n",
    "from clipreid.dataset import TestDataset, ChallengeDataset\n",
    "from clipreid.evaluator import predict, compute_dist_matrix, compute_scores, write_mat_csv\n",
    "from clipreid.utils import print_line\n",
    "\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    '''\n",
    "    --------------------------------------------------------------------------\n",
    "    Open Clip Models:\n",
    "    --------------------------------------------------------------------------    \n",
    "    - ('RN50', 'openai')\n",
    "    - ('RN50', 'yfcc15m')\n",
    "    - ('RN50', 'cc12m')\n",
    "    - ('RN50-quickgelu', 'openai')\n",
    "    - ('RN50-quickgelu', 'yfcc15m')\n",
    "    - ('RN50-quickgelu', 'cc12m')\n",
    "    - ('RN101', 'openai')\n",
    "    - ('RN101', 'yfcc15m')\n",
    "    - ('RN101-quickgelu', 'openai')\n",
    "    - ('RN101-quickgelu', 'yfcc15m')\n",
    "    - ('RN50x4', 'openai')\n",
    "    - ('RN50x16', 'openai')\n",
    "    - ('RN50x64', 'openai')\n",
    "    - ('ViT-B-32', 'openai')\n",
    "    - ('ViT-B-32', 'laion2b_e16')\n",
    "    - ('ViT-B-32', 'laion400m_e31')\n",
    "    - ('ViT-B-32', 'laion400m_e32')\n",
    "    - ('ViT-B-32-quickgelu', 'openai')\n",
    "    - ('ViT-B-32-quickgelu', 'laion400m_e31')\n",
    "    - ('ViT-B-32-quickgelu', 'laion400m_e32')\n",
    "    - ('ViT-B-16', 'openai')\n",
    "    - ('ViT-B-16', 'laion400m_e31')\n",
    "    - ('ViT-B-16', 'laion400m_e32')\n",
    "    - ('ViT-B-16-plus-240', 'laion400m_e31')\n",
    "    - ('ViT-B-16-plus-240', 'laion400m_e32')\n",
    "    - ('ViT-L-14', 'openai')\n",
    "    - ('ViT-L-14', 'laion400m_e31')\n",
    "    - ('ViT-L-14', 'laion400m_e32')\n",
    "    - ('ViT-L-14-336', 'openai')\n",
    "    - ('ViT-H-14', 'laion2b_s32b_b79k')\n",
    "    - ('ViT-g-14', 'laion2b_s12b_b42k')\n",
    "    --------------------------------------------------------------------------\n",
    "    Timm Models:\n",
    "    --------------------------------------------------------------------------\n",
    "    - 'convnext_base_in22ft1k'\n",
    "    - 'convnext_large_in22ft1k'\n",
    "    - 'vit_base_patch16_224'\n",
    "    - 'vit_large_patch16_224'\n",
    "    - ...\n",
    "    - https://github.com/rwightman/pytorch-image-models/blob/master/results/results-imagenet.csv\n",
    "    --------------------------------------------------------------------------\n",
    "    '''\n",
    "\n",
    "    # Model\n",
    "    model: tuple = ('ViT-L-14', 'openai')   # ('name of Clip model', 'name of dataset') | 'name of Timm model'\n",
    "    remove_proj: bool = True                # Remove projection for Clip ViT models\n",
    "\n",
    "    # Settings only for Timm models\n",
    "    img_size: tuple = (224, 224)             # Image size for Timm models\n",
    "    mean: tuple = (0.485, 0.456, 0.406)     # Mean of ImageNet\n",
    "    std: tuple = (0.229, 0.224, 0.225)      # Std of ImageNet\n",
    "\n",
    "    # Eval\n",
    "    batch_size: int = 64                    # Batch size for evaluation\n",
    "    normalize_features: bool = True         # L2 normalize features during eval  \n",
    "\n",
    "    # Split for Eval\n",
    "    fold: int = -1                          # -1 for given test split | int >=0 for custom folds \n",
    "\n",
    "    # Checkpoints: tuple of str for ensemble (checkpoint1, checkpoint2, ...)\n",
    "    checkpoints: tuple = (\n",
    "        \"./model_nsva/ViT-L-14_openai/fold0_seed_2024/weights_e4.pth\",\n",
    "        \"./model_nsva/ViT-L-14_openai/fold1_seed_2024/weights_e4.pth\"\n",
    "    )\n",
    "\n",
    "    # Dataset\n",
    "    data_dir: str = \"./data/nsva\"\n",
    "    challenge_csv: str = \"./data/nsva/challenge_df.csv\"\n",
    "\n",
    "    # Show progress bar\n",
    "    verbose: bool = True \n",
    "\n",
    "    # Set num_workers to 0 if OS is Windows\n",
    "    num_workers: int = 0 if os.name == 'nt' else 8  \n",
    "\n",
    "    # Use GPU if available\n",
    "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu' \n",
    "\n",
    "# Initialize configuration\n",
    "config = Configuration()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Model                                                                                                                #\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "\n",
    "print(\"\\nModel: {}\".format(config.model))\n",
    "\n",
    "if isinstance(config.model, tuple):\n",
    "    model = OpenClipModel(config.model[0],\n",
    "                          config.model[1],\n",
    "                          remove_proj=config.remove_proj)\n",
    "    \n",
    "    img_size = model.get_image_size()\n",
    "    \n",
    "    mean = (0.48145466, 0.4578275, 0.40821073)\n",
    "    std = (0.26862954, 0.26130258, 0.27577711)\n",
    "else:\n",
    "    model = TimmModel(config.model,\n",
    "                      pretrained=True)\n",
    "\n",
    "    img_size = config.img_size\n",
    "    mean = config.mean\n",
    "    std = config.std\n",
    "\n",
    "\n",
    "dist_matrix_list = []\n",
    "dist_matrix_rerank_list = []\n",
    "\n",
    "# Ensure checkpoints is a list\n",
    "if not isinstance(config.checkpoints, (list, tuple)):\n",
    "    checkpoints = [config.checkpoints]\n",
    "else:\n",
    "    checkpoints = config.checkpoints\n",
    "\n",
    "for checkpoint in checkpoints: \n",
    "\n",
    "    print_line(name=checkpoint, length=80)\n",
    "        \n",
    "    # Load pretrained Checkpoint     \n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(f\"Checkpoint '{checkpoint}' does not exist. Skipping.\")\n",
    "        continue\n",
    "    model_state_dict = torch.load(checkpoint, map_location=config.device)\n",
    "    model.load_state_dict(model_state_dict, strict=True)    \n",
    "      \n",
    "    # Model to device   \n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    print(\"\\nImage Size:\", img_size)\n",
    "    print(\"Mean: {}\".format(mean))\n",
    "    print(\"Std:  {}\".format(std)) \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # DataLoader                                                                                                       #\n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    \n",
    "    # Transforms\n",
    "    val_transforms, _ = get_transforms(img_size, mean, std)\n",
    "    \n",
    "    # Dataframes\n",
    "    train_df_path = os.path.join(config.data_dir, \"train_df.csv\")\n",
    "    challenge_df_path = config.challenge_csv\n",
    "    \n",
    "    if not os.path.exists(train_df_path):\n",
    "        print(f\"Training DataFrame not found at {train_df_path}\")\n",
    "        exit(1)\n",
    "    if not os.path.exists(challenge_df_path):\n",
    "        print(f\"Challenge DataFrame not found at {challenge_df_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    df_train = pd.read_csv(train_df_path)\n",
    "    df_challenge = pd.read_csv(challenge_df_path)\n",
    "     \n",
    "    if config.fold == -1:\n",
    "        # Use given test split\n",
    "        df_test = df_train[df_train[\"split\"] == \"test\"]\n",
    "    else:\n",
    "        # Use custom folds\n",
    "        df_test = df_train[df_train[\"fold\"] == config.fold]\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # Validation and Challenge                                                                                         #\n",
    "    #------------------------------------------------------------------------------------------------------------------#\n",
    "    test_dataset = TestDataset(img_path=config.data_dir,\n",
    "                               df=df_test,\n",
    "                               image_transforms=val_transforms)\n",
    "\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                             batch_size=config.batch_size,\n",
    "                             num_workers=config.num_workers,\n",
    "                             shuffle=False,\n",
    "                             pin_memory=True)\n",
    "\n",
    "    # Challenge\n",
    "    challenge_dataset = ChallengeDataset(df=df_challenge,\n",
    "                                         image_transforms=val_transforms)\n",
    "\n",
    "    challenge_loader = DataLoader(challenge_dataset,\n",
    "                                  batch_size=config.batch_size,\n",
    "                                  num_workers=config.num_workers,\n",
    "                                  shuffle=False,\n",
    "                                  pin_memory=True)\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # Test                                                                                                             #\n",
    "    #------------------------------------------------------------------------------------------------------------------# \n",
    "    print_line(name=\"Test Evaluation\", length=80)\n",
    "    \n",
    "    # Extract features for test set\n",
    "    features_dict = predict(model,\n",
    "                            dataloader=test_loader,\n",
    "                            device=config.device,\n",
    "                            normalize_features=config.normalize_features,\n",
    "                            verbose=config.verbose)\n",
    "    \n",
    "    # Compute distance matrix for test set\n",
    "    dist_matrix_test, dist_matrix_test_rerank = compute_dist_matrix(features_dict, \n",
    "                                                                    test_dataset.query,\n",
    "                                                                    test_dataset.gallery,\n",
    "                                                                    rerank=True)\n",
    "    \n",
    "    # Without re-ranking\n",
    "    print(\"\\nWithout re-ranking:\")\n",
    "    mAP_test = compute_scores(dist_matrix_test,\n",
    "                         test_dataset.query,\n",
    "                         test_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Test mAP: {mAP_test['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix without re-ranking\n",
    "    save_path_test = os.path.join(os.path.dirname(checkpoint), \"test_dmat.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_test)\n",
    "    write_mat_csv(save_path_test,\n",
    "                  dist_matrix_test,\n",
    "                  test_dataset.query,\n",
    "                  test_dataset.gallery) \n",
    "    \n",
    "    # With re-ranking\n",
    "    print(\"\\nWith re-ranking:\")\n",
    "    mAP_test_rerank = compute_scores(dist_matrix_test_rerank,\n",
    "                         test_dataset.query,\n",
    "                         test_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Test mAP with re-ranking: {mAP_test_rerank['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix with re-ranking\n",
    "    save_path_test_rerank = os.path.join(os.path.dirname(checkpoint), \"test_dmat_rerank.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_test_rerank)\n",
    "    write_mat_csv(save_path_test_rerank,\n",
    "                  dist_matrix_test_rerank,\n",
    "                  test_dataset.query,\n",
    "                  test_dataset.gallery) \n",
    "    \n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------------#  \n",
    "    # Challenge                                                                                                        #\n",
    "    #------------------------------------------------------------------------------------------------------------------#\n",
    "    print_line(name=\"Challenge Evaluation\", length=80)\n",
    "    \n",
    "    # Extract features for challenge set\n",
    "    features_dict_challenge = predict(model,\n",
    "                            dataloader=challenge_loader,\n",
    "                            device=config.device,\n",
    "                            normalize_features=config.normalize_features,\n",
    "                            verbose=config.verbose)\n",
    "    \n",
    "    # Compute distance matrix for challenge set\n",
    "    dist_matrix_challenge, dist_matrix_challenge_rerank = compute_dist_matrix(features_dict_challenge, \n",
    "                                                                                challenge_dataset.query,\n",
    "                                                                                challenge_dataset.gallery,\n",
    "                                                                                rerank=True)\n",
    "    \n",
    "    # Collect for ensemble\n",
    "    if not dist_matrix_challenge.size == 0:\n",
    "        dist_matrix_list.append(dist_matrix_challenge)\n",
    "    if dist_matrix_challenge_rerank.size != 0:\n",
    "        dist_matrix_rerank_list.append(dist_matrix_challenge_rerank)\n",
    "    \n",
    "    # Compute and print scores for challenge set without re-ranking\n",
    "    print(\"\\nChallenge Set without re-ranking:\")\n",
    "    mAP_challenge = compute_scores(dist_matrix_challenge,\n",
    "                         challenge_dataset.query,\n",
    "                         challenge_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Challenge mAP: {mAP_challenge['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix without re-ranking for challenge\n",
    "    save_path_challenge = os.path.join(os.path.dirname(checkpoint), \"challenge_dmat.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_challenge)\n",
    "    write_mat_csv(save_path_challenge,\n",
    "                  dist_matrix_challenge,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery) \n",
    "    \n",
    "    # Compute and print scores for challenge set with re-ranking\n",
    "    print(\"\\nChallenge Set with re-ranking:\")\n",
    "    mAP_challenge_rerank = compute_scores(dist_matrix_challenge_rerank,\n",
    "                         challenge_dataset.query,\n",
    "                         challenge_dataset.gallery,\n",
    "                         cmc_scores=True)\n",
    "\n",
    "    print(f\"Challenge mAP with re-ranking: {mAP_challenge_rerank['mAP']:.4f}\")\n",
    "    \n",
    "    # Save distance matrix with re-ranking for challenge\n",
    "    save_path_challenge_rerank = os.path.join(os.path.dirname(checkpoint), \"challenge_dmat_rerank.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_challenge_rerank)\n",
    "    write_mat_csv(save_path_challenge_rerank,\n",
    "                  dist_matrix_challenge_rerank,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery)\n",
    "    \n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#  \n",
    "# Ensemble                                                                                                             #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "if len(dist_matrix_list) > 1:\n",
    "    \n",
    "    print_line(name=\"Ensemble\", length=80)\n",
    "    \n",
    "    # Without re-ranking\n",
    "    dist_matrix_ensemble = np.stack(dist_matrix_list, axis=0).mean(0)\n",
    "    save_path_ensemble = os.path.join(os.path.dirname(config.checkpoints[0]), \"challenge_dmat_ensemble.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_ensemble)\n",
    "    write_mat_csv(save_path_ensemble,\n",
    "                  dist_matrix_ensemble,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery) \n",
    "    \n",
    "    # With re-ranking\n",
    "    dist_matrix_rerank_ensemble = np.stack(dist_matrix_rerank_list, axis=0).mean(0)\n",
    "    save_path_rerank_ensemble = os.path.join(os.path.dirname(config.checkpoints[0]), \"challenge_dmat_rerank_ensemble.csv\")\n",
    "    print(\"Writing distance matrix:\", save_path_rerank_ensemble)\n",
    "    write_mat_csv(save_path_rerank_ensemble,\n",
    "                  dist_matrix_rerank_ensemble,\n",
    "                  challenge_dataset.query,\n",
    "                  challenge_dataset.gallery) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding generator\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def simplify_color(color):\n",
    "    \"\"\"\n",
    "    Simplify the color names to a standard set.\n",
    "    \"\"\"\n",
    "    color_map = {\n",
    "        'dark blue': 'blue',\n",
    "        'light blue': 'blue',\n",
    "        'navy': 'blue',\n",
    "        'dark red': 'red',\n",
    "        'maroon': 'red',\n",
    "        'burgundy': 'red',\n",
    "        'forest green': 'green',\n",
    "        'lime green': 'green',\n",
    "        'olive': 'green',\n",
    "        'dark purple': 'purple',\n",
    "        'lavender': 'purple',\n",
    "        'gold': 'yellow',\n",
    "        'beige': 'tan',\n",
    "        'grey': 'gray',\n",
    "        'charcoal': 'gray',\n",
    "        'silver': 'gray',\n",
    "        'white': 'white',\n",
    "        'blue': 'blue',\n",
    "        'black': 'black',\n",
    "        'green': 'green',\n",
    "        'orange': 'orange',\n",
    "        'red': 'red',\n",
    "        'yellow': 'yellow'\n",
    "    }\n",
    "    return color_map.get(color.lower(), color.lower())\n",
    "\n",
    "def number_to_words(number):\n",
    "    \"\"\"\n",
    "    Convert a number to its word representation.\n",
    "    \"\"\"\n",
    "    units = [\"\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "    teens = [\"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \n",
    "             \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"]\n",
    "    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \n",
    "            \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "    \n",
    "    if 0 <= number < 10:\n",
    "        return units[number]\n",
    "    elif 10 <= number < 20:\n",
    "        return teens[number - 10]\n",
    "    elif 20 <= number < 100:\n",
    "        ten, unit = divmod(number, 10)\n",
    "        return tens[ten] + (\"-\" + units[unit] if unit else \"\")\n",
    "    else:\n",
    "        return str(number)\n",
    "\n",
    "class GamePlayerAttributeGenerator:\n",
    "    \"\"\"\n",
    "    Generates a game-player attribute dictionary and creates embeddings for jersey number,\n",
    "    jersey color, and ethnicity using CLIP's zero-shot capabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, clip_model_name=\"ViT-L/14\", output_dir=\"output_embeds\", use_words_for_numbers=False):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.clip_model, self.preprocess = clip.load(clip_model_name, device=self.device)\n",
    "        self.output_dir = output_dir\n",
    "        self.embeddings_dir = os.path.join(output_dir, \"embeddings\")\n",
    "        os.makedirs(self.embeddings_dir, exist_ok=True)\n",
    "        self.use_words_for_numbers = use_words_for_numbers\n",
    "        self.game_player_attribute = {}\n",
    "        self.unique_attributes = {\n",
    "            \"jersey_number\": set(),\n",
    "            \"jersey_color\": set(),\n",
    "            \"ethnicity\": set()\n",
    "        }\n",
    "\n",
    "    def get_text_embedding(self, text):\n",
    "        \"\"\"\n",
    "        Generate text embedding using CLIP.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            text_tokens = clip.tokenize([text]).to(self.device)\n",
    "            text_embedding = self.clip_model.encode_text(text_tokens)\n",
    "        return text_embedding.cpu().numpy()[0]\n",
    "\n",
    "    def build_game_player_attribute(self, player_data, game_data):\n",
    "        \"\"\"\n",
    "        Build the game_player_attribute dictionary based on player and game data.\n",
    "        \"\"\"\n",
    "        for game_id, game_info in game_data.items():\n",
    "            teamA = game_info['teamA']\n",
    "            teamB = game_info['teamB']\n",
    "            colorA = simplify_color(game_info['colorA'])\n",
    "            colorB = simplify_color(game_info['colorB'])\n",
    "\n",
    "            self.game_player_attribute[game_id] = {\n",
    "                \"teamA\": teamA,\n",
    "                \"teamB\": teamB,\n",
    "                \"colorA\": colorA,\n",
    "                \"colorB\": colorB,\n",
    "                \"players\": {}\n",
    "            }\n",
    "\n",
    "            # Find players in teamA and teamB\n",
    "            for player_name, player_info in player_data.items():\n",
    "                team_name = player_info['team_name']\n",
    "                if team_name == teamA:\n",
    "                    jersey_color = colorA\n",
    "                elif team_name == teamB:\n",
    "                    jersey_color = colorB\n",
    "                else:\n",
    "                    continue  # Player not in this game\n",
    "\n",
    "                jersey_number = player_info['jersey_number']\n",
    "                ethnicity = player_info['ethnicity']\n",
    "\n",
    "                # Simplify jersey color\n",
    "                jersey_color_simplified = simplify_color(jersey_color)\n",
    "\n",
    "                # Handle jersey number representation\n",
    "                if re.match(r'^0\\d+$', jersey_number):\n",
    "                    # If jersey number starts with '0' and has multiple digits\n",
    "                    jersey_number_digits = ' '.join(jersey_number)\n",
    "                    jersey_number_words = ' '.join([number_to_words(int(digit)) for digit in jersey_number])\n",
    "                else:\n",
    "                    jersey_number_digits = jersey_number\n",
    "                    jersey_number_words = number_to_words(int(jersey_number))\n",
    "\n",
    "                if self.use_words_for_numbers:\n",
    "                    jersey_number_repr = jersey_number_words\n",
    "                else:\n",
    "                    jersey_number_repr = jersey_number_digits\n",
    "\n",
    "                # Populate the game_player_attribute dictionary\n",
    "                self.game_player_attribute[game_id][\"players\"][player_name] = {\n",
    "                    \"jersey_color\": jersey_color_simplified,\n",
    "                    \"jersey_number\": jersey_number_repr,\n",
    "                    \"ethnicity\": ethnicity.lower()\n",
    "                }\n",
    "\n",
    "                # Collect unique attribute values\n",
    "                self.unique_attributes[\"jersey_color\"].add(jersey_color_simplified)\n",
    "                self.unique_attributes[\"jersey_number\"].add(jersey_number_repr)\n",
    "                self.unique_attributes[\"ethnicity\"].add(ethnicity.lower())\n",
    "\n",
    "    def generate_embeddings(self):\n",
    "        \"\"\"\n",
    "        Generate and save embeddings for all unique attribute values.\n",
    "        \"\"\"\n",
    "        attribute_descriptions = {\n",
    "            \"jersey_number\": \"a basketball player with jersey number {}\",\n",
    "            \"jersey_color\": \"a {} jersey, color {}\",\n",
    "            \"ethnicity\": \"a {} basketball player\"\n",
    "        }\n",
    "\n",
    "        for attribute, values in self.unique_attributes.items():\n",
    "            for value in values:\n",
    "                if attribute == \"jersey_color\":\n",
    "                    description = attribute_descriptions[attribute].format(value, value)\n",
    "                else:\n",
    "                    description = attribute_descriptions[attribute].format(value)\n",
    "\n",
    "                embedding = self.get_text_embedding(description)\n",
    "\n",
    "                # Define embedding filename\n",
    "                filename = f\"{attribute}_{value.replace(' ', '_')}.npy\"\n",
    "                file_path = os.path.join(self.embeddings_dir, filename)\n",
    "                np.save(file_path, embedding)\n",
    "\n",
    "    def save_game_player_attribute(self):\n",
    "        \"\"\"\n",
    "        Save the game_player_attribute dictionary to a JSON file.\n",
    "        \"\"\"\n",
    "        save_path = os.path.join(self.output_dir, 'game_player_attribute.json')\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(self.game_player_attribute, f, indent=2)\n",
    "        print(f\"game_player_attribute.json has been saved to {save_path}\")\n",
    "\n",
    "    def save_embeddings_info(self):\n",
    "        \"\"\"\n",
    "        Save a mapping of attribute values to their embedding filenames.\n",
    "        This can be useful for reference.\n",
    "        \"\"\"\n",
    "        embedding_info = defaultdict(dict)\n",
    "        for attribute in self.unique_attributes:\n",
    "            for value in self.unique_attributes[attribute]:\n",
    "                filename = f\"{attribute}_{value.replace(' ', '_')}.npy\"\n",
    "                embedding_info[attribute][value] = os.path.join(\"embeddings\", filename)\n",
    "        \n",
    "        save_path = os.path.join(self.output_dir, 'embedding_info.json')\n",
    "        with open(save_path, 'w') as f:\n",
    "            json.dump(embedding_info, f, indent=2)\n",
    "        print(f\"embedding_info.json has been saved to {save_path}\")\n",
    "\n",
    "    def run(self, player_data_path, game_data_path):\n",
    "        \"\"\"\n",
    "        Execute the entire pipeline: load data, build dictionary, generate embeddings, and save outputs.\n",
    "        \"\"\"\n",
    "        # Load JSON data\n",
    "        with open(player_data_path, 'r') as f:\n",
    "            player_data = json.load(f)\n",
    "        \n",
    "        with open(game_data_path, 'r') as f:\n",
    "            game_data = json.load(f)\n",
    "\n",
    "        # Build the game_player_attribute dictionary\n",
    "        self.build_game_player_attribute(player_data, game_data)\n",
    "\n",
    "        # Generate embeddings for unique attribute values\n",
    "        self.generate_embeddings()\n",
    "\n",
    "        # Save the game_player_attribute dictionary\n",
    "        self.save_game_player_attribute()\n",
    "\n",
    "        # Save embedding information\n",
    "        self.save_embeddings_info()\n",
    "\n",
    "        print(f\"All embeddings have been saved in the '{self.embeddings_dir}' directory\")\n",
    "        print(f\"game_player_attribute.json and embedding_info.json have been saved in the '{self.output_dir}' directory\")\n",
    "\n",
    "def main(player_data_path, game_data_path, output_dir, use_words_for_numbers=False):\n",
    "    \"\"\"\n",
    "    Main function to initialize the generator and execute the process.\n",
    "    \"\"\"\n",
    "    # Initialize the generator with the specified CLIP model\n",
    "    generator = GamePlayerAttributeGenerator(\n",
    "        clip_model_name=\"ViT-L/14\",  # Using the same model as in training\n",
    "        output_dir=output_dir, \n",
    "        use_words_for_numbers=use_words_for_numbers\n",
    "    )\n",
    "\n",
    "    # Run the generator\n",
    "    generator.run(player_data_path, game_data_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths\n",
    "    player_data_path = '/home/minxing/code/NSVA_MOTR/tools/player_summaries_final.json'\n",
    "    game_data_path = '/home/minxing/code/NSVA_MOTR/tools/game_teams_summaries_1.json'\n",
    "    output_dir = 'output_embeds'  # You can change this to your desired output location\n",
    "    use_words_for_numbers = False  # Set to True if you want to use words for numbers\n",
    "\n",
    "    # Execute main function\n",
    "    main(player_data_path, game_data_path, output_dir, use_words_for_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessing large scale\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass, field\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class Configuration:\n",
    "    data_dir: str = \"/home/minxing/datasets/NSVA_157_zeroshot_crops_new/player_crops\"\n",
    "    save_dir: str = \"./data/nsva_txt_img\"\n",
    "    selected_game_endings: list = field(default_factory=lambda: ['00160', '00060', '01212', '01055'])\n",
    "    seed: int = 2024  # Seed for reproducibility\n",
    "    num_workers: int = 8  # Adjust based on your system\n",
    "\n",
    "# Initialize configuration\n",
    "config = Configuration()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(config.seed)\n",
    "random.seed(config.seed)\n",
    "\n",
    "# Create the save directory if it doesn't exist\n",
    "os.makedirs(config.save_dir, exist_ok=True)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Function to build the DataFrame with all crops excluding player ID 0                                                  #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "def build_dataframe(base_path, selected_game_endings):\n",
    "    img_id = []\n",
    "    folder = []\n",
    "    player = []\n",
    "    game = []\n",
    "    img_type = []\n",
    "    split = []\n",
    "    \n",
    "    # Iterate through each game_play directory\n",
    "    for game_play_dir in os.listdir(base_path):\n",
    "        game_play_path = os.path.join(base_path, game_play_dir)\n",
    "        \n",
    "        if os.path.isdir(game_play_path):\n",
    "            # Extract game_id from the directory name\n",
    "            if '-' not in game_play_dir:\n",
    "                print(f\"Skipping directory '{game_play_dir}' as it does not contain a hyphen '-'.\")\n",
    "                continue  # Skip directories that don't follow the 'game_id-play_id' format\n",
    "            \n",
    "            game_id_full = game_play_dir.split('-')[0]\n",
    "            game_id = game_id_full  # Use the full game_id\n",
    "            \n",
    "            # Check if game_id ends with one of the selected endings\n",
    "            if not any(game_id.endswith(ending) for ending in selected_game_endings):\n",
    "                continue  # Skip games not in the selected list\n",
    "            \n",
    "            # Debugging: Print matched game_play_dir\n",
    "            # print(f\"Matched game_play_dir: '{game_play_dir}' with game_id: '{game_id}'\")\n",
    "            \n",
    "            # Iterate through player directories inside each game-play directory\n",
    "            for player_id in os.listdir(game_play_path):\n",
    "                if player_id == '0':\n",
    "                    continue  # Skip player ID 0\n",
    "                \n",
    "                player_dir_path = os.path.join(game_play_path, player_id)\n",
    "                \n",
    "                if os.path.isdir(player_dir_path):\n",
    "                    # Get all image files in the player directory\n",
    "                    image_files = [f for f in os.listdir(player_dir_path) if os.path.isfile(os.path.join(player_dir_path, f))]\n",
    "                    \n",
    "                    # Iterate through image files\n",
    "                    for image_file in image_files:\n",
    "                        image_path = os.path.join(player_dir_path, image_file)\n",
    "                        if os.path.isfile(image_path):\n",
    "                            # Extract image information\n",
    "                            img_id.append(os.path.splitext(image_file)[0])  # Remove file extension\n",
    "                            folder.append(player_dir_path)  # Full path to the player's directory\n",
    "                            player.append(player_id)\n",
    "                            game.append(game_id)\n",
    "                            split.append('all')  # Will update later\n",
    "                            img_type.append('g')  # Default to 'g'; will adjust later\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"img_id\": img_id,\n",
    "        \"folder\": folder,  # Full path to the player's directory\n",
    "        \"player\": player,\n",
    "        \"game\": game,\n",
    "        \"split\": split,\n",
    "        \"img_type\": img_type,\n",
    "    })\n",
    "\n",
    "    # print(f\"Total images collected from selected games: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Build DataFrame for Selected Games                                                                                   #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Build DataFrame from both train and test directories\n",
    "df_train = build_dataframe(os.path.join(config.data_dir, 'train'), config.selected_game_endings)\n",
    "df_test = build_dataframe(os.path.join(config.data_dir, 'test'), config.selected_game_endings)\n",
    "\n",
    "# Combine the dataframes\n",
    "df_full = pd.concat([df_train, df_test], ignore_index=True)\n",
    "print(f\"Combined DataFrame contains {len(df_full)} images.\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Assign Splits (80% Train, 20% Test) for Each Player                                                                  #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Convert 'player' column to int for proper grouping\n",
    "df_full['player'] = df_full['player'].astype(int)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df_full = df_full.sample(frac=1, random_state=config.seed).reset_index(drop=True)\n",
    "\n",
    "# Assign splits for each player\n",
    "df_full['split'] = 'train'  # Initialize all as 'train'\n",
    "\n",
    "players = df_full['player'].unique()\n",
    "for player_id in players:\n",
    "    player_indices = df_full[df_full['player'] == player_id].index\n",
    "    player_data = df_full.loc[player_indices]\n",
    "    if len(player_data) >= 5:  # Ensure there are enough samples to split\n",
    "        train_indices, test_indices = train_test_split(\n",
    "            player_indices,\n",
    "            test_size=0.2,\n",
    "            random_state=config.seed\n",
    "        )\n",
    "        df_full.loc[test_indices, 'split'] = 'test'\n",
    "    else:\n",
    "        # If not enough samples, assign all to train\n",
    "        print(f\"Player {player_id} has only {len(player_data)} samples. Assigning all to 'train'.\")\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Map player IDs to integer labels starting from 0                                                                     #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Map players to unique IDs starting from 0\n",
    "unique_players = df_full['player'].unique()\n",
    "player_id_map = {player_id: idx for idx, player_id in enumerate(unique_players)}\n",
    "df_full['player'] = df_full['player'].map(player_id_map).astype(int)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Save DataFrame                                                                                                       #\n",
    "#----------------------------------------------------------------------------------------------------------------------#\n",
    "# Save the combined DataFrame\n",
    "train_df_path_saved = os.path.join(config.save_dir, \"train_df.csv\")\n",
    "df_full.to_csv(train_df_path_saved, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nDataFrame saved:\")\n",
    "print(f\" - DataFrame: {train_df_path_saved}\")\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Number of total images: {len(df_full)}\")\n",
    "print(f\"Number of training images: {len(df_full[df_full['split'] == 'train'])}\")\n",
    "print(f\"Number of testing images: {len(df_full[df_full['split'] == 'test'])}\")\n",
    "print(f\"Number of unique players: {df_full['player'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Images: 100%|██████████| 15193/15193 [02:22<00:00, 106.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# zero_shot_classification_revised_with_topk.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "import clip\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import re\n",
    "import ast  # For safely evaluating string representations of lists\n",
    "\n",
    "# ------------------------ Configuration Class ------------------------\n",
    "\n",
    "class Configuration:\n",
    "    # Model configurations\n",
    "    model: str = ('ViT-L/14', 'openai')  # Default to ViT-L/14\n",
    "    remove_proj = True\n",
    "    img_size: int = (224, 224)\n",
    "    mean:   float = (0.485, 0.456, 0.406)\n",
    "    std:    float = (0.229, 0.224, 0.225)\n",
    "    \n",
    "    # Data settings\n",
    "    seed: int = 2024\n",
    "    batch_size_eval: int = 64\n",
    "    device: str = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    data_csv: str = \"./data/nsva/train_df.csv\"\n",
    "    output_folder: str = 'output_embeds'\n",
    "    split: str = 'train'  # 'train' or 'test'\n",
    "\n",
    "config = Configuration()\n",
    "\n",
    "# ------------------------ Helper Functions ------------------------\n",
    "\n",
    "def clean_player_name(player_name):\n",
    "    \"\"\"\n",
    "    Clean player names by removing non-alphabetic characters and extra spaces.\n",
    "    \"\"\"\n",
    "    cleaned_name = re.sub(r'[^A-Za-z ]', '', player_name)\n",
    "    cleaned_name = ' '.join(cleaned_name.split())\n",
    "    return cleaned_name.strip().lower()\n",
    "\n",
    "def load_player_summaries(player_summaries_file):\n",
    "    \"\"\"\n",
    "    Load player summaries from player_summaries_final.json.\n",
    "    \"\"\"\n",
    "    with open(player_summaries_file, 'r') as f:\n",
    "        player_summaries = json.load(f)\n",
    "    return player_summaries\n",
    "\n",
    "def load_labels(labels_file):\n",
    "    \"\"\"\n",
    "    Load labels from ZeroShotDataset_labels.txt.\n",
    "    Each line in the file corresponds to a player with format: ID_PlayerName_JerseyNumber\n",
    "    \"\"\"\n",
    "    labels = {}\n",
    "    with open(labels_file, 'r') as f:\n",
    "        for idx, line in enumerate(f, start=1): \n",
    "            parts = line.strip().split('_')\n",
    "            if len(parts) < 3:\n",
    "                print(f\"Skipping malformed line {idx}: {line.strip()}\")\n",
    "                continue\n",
    "            player_name = ' '.join(parts[1:-1])\n",
    "            jersey_number = parts[-1]  \n",
    "            labels[str(idx)] = {\n",
    "                'player_name': player_name,\n",
    "                'jersey_number': jersey_number\n",
    "            }\n",
    "    return labels\n",
    "\n",
    "def create_attribute_classes(embedding_info):\n",
    "    \"\"\"\n",
    "    Create unique class descriptions for each attribute from embedding_info.\n",
    "    \"\"\"\n",
    "    jersey_color_values = embedding_info['jersey_color'].keys()\n",
    "    jersey_number_values = embedding_info['jersey_number'].keys()\n",
    "    ethnicity_values = embedding_info['ethnicity'].keys()\n",
    "\n",
    "    # Create descriptions\n",
    "    jersey_color_descriptions = [f\"a {color} jersey, color {color}\" for color in sorted(jersey_color_values)]\n",
    "    jersey_number_descriptions = [\n",
    "        f\"a basketball player with jersey number {number}\" \n",
    "        for number in sorted(jersey_number_values, key=lambda x: int(x) if x.isdigit() else float('inf'))\n",
    "    ]\n",
    "    ethnicity_descriptions = [f\"a {ethnicity} basketball player\" for ethnicity in sorted(ethnicity_values)]\n",
    "    \n",
    "    return jersey_color_descriptions, jersey_number_descriptions, ethnicity_descriptions\n",
    "\n",
    "def encode_class_descriptions(clip_model, device, jersey_color_descriptions, jersey_number_descriptions, ethnicity_descriptions):\n",
    "    \"\"\"\n",
    "    Encode class descriptions using CLIP and return normalized embeddings.\n",
    "    \"\"\"\n",
    "    class_embeddings = {}\n",
    "    \n",
    "    # Encode jersey colors\n",
    "    with torch.no_grad():\n",
    "        jersey_color_tokens = clip.tokenize(jersey_color_descriptions).to(device)\n",
    "        jersey_color_embeddings = clip_model.encode_text(jersey_color_tokens)\n",
    "        jersey_color_embeddings /= jersey_color_embeddings.norm(dim=-1, keepdim=True)\n",
    "        class_embeddings['jersey_color'] = {\n",
    "            desc: emb.cpu().numpy() for desc, emb in zip(jersey_color_descriptions, jersey_color_embeddings)\n",
    "        }\n",
    "    \n",
    "    # Encode jersey numbers\n",
    "    with torch.no_grad():\n",
    "        jersey_number_tokens = clip.tokenize(jersey_number_descriptions).to(device)\n",
    "        jersey_number_embeddings = clip_model.encode_text(jersey_number_tokens)\n",
    "        jersey_number_embeddings /= jersey_number_embeddings.norm(dim=-1, keepdim=True)\n",
    "        class_embeddings['jersey_number'] = {\n",
    "            desc: emb.cpu().numpy() for desc, emb in zip(jersey_number_descriptions, jersey_number_embeddings)\n",
    "        }\n",
    "    \n",
    "    # Encode ethnicities\n",
    "    with torch.no_grad():\n",
    "        ethnicity_tokens = clip.tokenize(ethnicity_descriptions).to(device)\n",
    "        ethnicity_embeddings = clip_model.encode_text(ethnicity_tokens)\n",
    "        ethnicity_embeddings /= ethnicity_embeddings.norm(dim=-1, keepdim=True)\n",
    "        class_embeddings['ethnicity'] = {\n",
    "            desc: emb.cpu().numpy() for desc, emb in zip(ethnicity_descriptions, ethnicity_embeddings)\n",
    "        }\n",
    "    \n",
    "    return class_embeddings\n",
    "\n",
    "def zero_shot_classification(image_path, clip_model, preprocess, device, class_embeddings):\n",
    "    \"\"\"\n",
    "    Perform zero-shot classification on a single image for all attributes.\n",
    "    Returns top-1 and top-K predictions as required.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n",
    "        return {\n",
    "            'jersey_color_top1': 'unknown',\n",
    "            'jersey_color_top2': ['unknown'],\n",
    "            'jersey_number_top1': 'unknown',\n",
    "            'jersey_number_top3': ['unknown'],\n",
    "            'ethnicity': 'unknown'\n",
    "        }\n",
    "    \n",
    "    image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_embedding = clip_model.encode_image(image_input)\n",
    "        image_embedding /= image_embedding.norm(dim=-1, keepdim=True)\n",
    "        image_embedding = image_embedding.cpu().numpy()\n",
    "    \n",
    "    predictions = {}\n",
    "    \n",
    "    for attr, classes in class_embeddings.items():\n",
    "        class_embeds = np.array(list(classes.values()))\n",
    "        similarities = np.dot(class_embeds, image_embedding.T).flatten()\n",
    "        \n",
    "        if attr == 'jersey_color':\n",
    "            top_k = 2\n",
    "        elif attr == 'jersey_number':\n",
    "            top_k = 3\n",
    "        else:\n",
    "            top_k = 1  # For ethnicity\n",
    "        \n",
    "        top_indices = np.argsort(-similarities)[:top_k]\n",
    "        top_classes = [list(classes.keys())[i] for i in top_indices]\n",
    "        \n",
    "        values = []\n",
    "        for top_class in top_classes:\n",
    "            if attr == 'jersey_color':\n",
    "                # Description format: \"a blue jersey, color blue\"\n",
    "                # Extract the color\n",
    "                parts = top_class.split(',')\n",
    "                if len(parts) >= 2:\n",
    "                    # \"a blue jersey, color blue\" -> ' color blue' -> 'blue'\n",
    "                    color_part = parts[1].strip()\n",
    "                    value = color_part.split()[1] if len(color_part.split()) >= 2 else 'unknown'\n",
    "                else:\n",
    "                    value = top_class.split()[1] if len(top_class.split()) >= 2 else 'unknown'\n",
    "            elif attr == 'jersey_number':\n",
    "                # Description format: \"a basketball player with jersey number 23\"\n",
    "                # Extract the number\n",
    "                value = top_class.split()[-1] if len(top_class.split()) >=1 else 'unknown'\n",
    "            elif attr == 'ethnicity':\n",
    "                # Description format: \"a black basketball player\"\n",
    "                # Extract only the ethnicity\n",
    "                value = top_class.split()[1] if len(top_class.split()) > 1 else 'unknown'\n",
    "            else:\n",
    "                value = 'unknown'\n",
    "            values.append(value.lower())\n",
    "        \n",
    "        if attr == 'jersey_color':\n",
    "            predictions['jersey_color_top1'] = values[0] if len(values) >=1 else 'unknown'  # Top-1\n",
    "            predictions['jersey_color_top2'] = values[:2] if len(values) >=2 else values      # Top-2\n",
    "        elif attr == 'jersey_number':\n",
    "            predictions['jersey_number_top1'] = values[0] if len(values) >=1 else 'unknown'  # Top-1\n",
    "            predictions['jersey_number_top3'] = values[:3] if len(values) >=3 else values     # Top-3\n",
    "        else:\n",
    "            predictions['ethnicity'] = values[0] if len(values) >=1 else 'unknown'           # Single value for ethnicity\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def evaluate_predictions(predictions_df):\n",
    "    \"\"\"\n",
    "    Evaluate the classification predictions and return metrics.\n",
    "    Handles both Top-1 and Top-K evaluations.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for attr in ['jersey_color', 'jersey_number', 'ethnicity']:\n",
    "        try:\n",
    "            if attr == 'jersey_color':\n",
    "                top_k = 2\n",
    "                top_k_column = f'predicted_{attr}_top{top_k}'\n",
    "                predicted_top1_col = f'predicted_{attr}_top1'\n",
    "            elif attr == 'jersey_number':\n",
    "                top_k = 3\n",
    "                top_k_column = f'predicted_{attr}_top{top_k}'\n",
    "                predicted_top1_col = f'predicted_{attr}_top1'\n",
    "            else:\n",
    "                top_k = 1  # For ethnicity, only Top-1\n",
    "                top_k_column = None\n",
    "                predicted_top1_col = f'predicted_{attr}'\n",
    "\n",
    "            # Top-1 evaluation\n",
    "            ground_truth = predictions_df[f'ground_truth_{attr}'].astype(str).str.lower().str.strip()\n",
    "            predicted_top1 = predictions_df[predicted_top1_col].astype(str).str.lower().str.strip()\n",
    "            \n",
    "            acc_top1 = accuracy_score(ground_truth, predicted_top1)\n",
    "            precision_top1, recall_top1, f1_top1, _ = precision_recall_fscore_support(\n",
    "                ground_truth, predicted_top1, average='weighted', zero_division=0\n",
    "            )\n",
    "            \n",
    "            metrics[attr] = {\n",
    "                'top1_accuracy': acc_top1,\n",
    "                'top1_precision': precision_top1,\n",
    "                'top1_recall': recall_top1,\n",
    "                'top1_f1_score': f1_top1\n",
    "            }\n",
    "            \n",
    "            # Top-K evaluation where applicable\n",
    "            if top_k > 1 and top_k_column in predictions_df.columns:\n",
    "                # Convert string representations of lists back to actual lists\n",
    "                predictions_df[top_k_column] = predictions_df[top_k_column].apply(\n",
    "                    lambda x: ast.literal_eval(x) if isinstance(x, str) else (x if isinstance(x, list) else [])\n",
    "                )\n",
    "                \n",
    "                # Normalize predicted lists\n",
    "                predictions_df[top_k_column] = predictions_df[top_k_column].apply(\n",
    "                    lambda x: [str(item).lower().strip() for item in x]\n",
    "                )\n",
    "                \n",
    "                # Check if ground truth is in the top-K predictions\n",
    "                top_k_correct = predictions_df.apply(\n",
    "                    lambda row: row[f'ground_truth_{attr}'] in row[top_k_column],\n",
    "                    axis=1\n",
    "                )\n",
    "                acc_topk = top_k_correct.mean()\n",
    "                metrics[attr][f'top{top_k}_accuracy'] = acc_topk\n",
    "        except KeyError as e:\n",
    "            print(f\"Error evaluating attribute '{attr}': {e}\")\n",
    "            metrics[attr] = {'top1_accuracy': 0.0}\n",
    "            if top_k > 1:\n",
    "                metrics[attr][f'top{top_k}_accuracy'] = 0.0\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error evaluating attribute '{attr}': {e}\")\n",
    "            metrics[attr] = {'top1_accuracy': 0.0}\n",
    "            if top_k > 1:\n",
    "                metrics[attr][f'top{top_k}_accuracy'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# ------------------------ Main Classification Task ------------------------\n",
    "\n",
    "def classification_task(\n",
    "    labels_file,\n",
    "    player_summaries_file,\n",
    "    game_player_attribute_path,\n",
    "    embedding_info_path,\n",
    "    data_csv_path,\n",
    "    output_folder,\n",
    "    split='test'\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform zero-shot attribute classification on specified data splits.\n",
    "    \"\"\"\n",
    "    # Redirect stdout to log file\n",
    "    log_file_path = os.path.join(output_folder, f'ZS_log_full_{split}.txt')\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open(log_file_path, 'w')\n",
    "    \n",
    "    # ------------------------ Data Loading ------------------------\n",
    "    \n",
    "    # Load labels\n",
    "    print(\"Loading labels...\")\n",
    "    labels = load_labels(labels_file)\n",
    "    print(f\"Total labels loaded: {len(labels)}\")\n",
    "    \n",
    "    # Load player summaries\n",
    "    print(\"Loading player summaries...\")\n",
    "    player_summaries = load_player_summaries(player_summaries_file)\n",
    "    print(f\"Total player summaries loaded: {len(player_summaries)}\")\n",
    "    \n",
    "    # Load game_player_attribute\n",
    "    print(\"Loading game_player_attribute...\")\n",
    "    with open(game_player_attribute_path, 'r') as f:\n",
    "        game_player_attribute = json.load(f)\n",
    "    print(f\"Total games loaded: {len(game_player_attribute)}\")\n",
    "    \n",
    "    # Load embedding_info\n",
    "    print(\"Loading embedding_info...\")\n",
    "    with open(embedding_info_path, 'r') as f:\n",
    "        embedding_info = json.load(f)\n",
    "    print(f\"Total embedding mappings loaded: {len(embedding_info)}\")\n",
    "    \n",
    "    # ------------------------ Attribute Class Creation ------------------------\n",
    "    \n",
    "    # Create per-class attribute descriptions\n",
    "    print(\"Creating attribute classes...\")\n",
    "    jersey_color_desc, jersey_number_desc, ethnicity_desc = create_attribute_classes(embedding_info)\n",
    "    print(f\"Jersey Colors Descriptions: {jersey_color_desc}\")\n",
    "    print(f\"Jersey Numbers Descriptions: {jersey_number_desc}\")\n",
    "    print(f\"Ethnicities Descriptions: {ethnicity_desc}\")\n",
    "    \n",
    "    # ------------------------ CLIP Model Loading ------------------------\n",
    "    \n",
    "    # Load CLIP model\n",
    "    print(\"Loading CLIP model...\")\n",
    "    device = config.device\n",
    "    clip_model_name = config.model[0]\n",
    "    clip_model, preprocess = clip.load(clip_model_name, device=device)\n",
    "    print(f\"CLIP model '{clip_model_name}' loaded on {device}\")\n",
    "    \n",
    "    # Encode class descriptions\n",
    "    print(\"Encoding class descriptions...\")\n",
    "    class_embeddings = encode_class_descriptions(\n",
    "        clip_model, device, jersey_color_desc, jersey_number_desc, ethnicity_desc\n",
    "    )\n",
    "    print(\"Class descriptions encoded successfully.\")\n",
    "    \n",
    "    # ------------------------ DataFrame Loading ------------------------\n",
    "    \n",
    "    # Load the data CSV\n",
    "    print(f\"Loading data from {data_csv_path}...\")\n",
    "    df_full = pd.read_csv(data_csv_path)\n",
    "    \n",
    "    if split not in ['train', 'test']:\n",
    "        print(f\"Invalid split '{split}'. Choose from 'train' or 'test'.\")\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = original_stdout\n",
    "        return\n",
    "    \n",
    "    df_split = df_full[df_full['split'] == split].reset_index(drop=True)\n",
    "    print(f\"Total images in '{split}' split: {len(df_split)}\")\n",
    "    \n",
    "    # ------------------------ Zero-Shot Classification ------------------------\n",
    "    \n",
    "    # Initialize a list to collect predictions\n",
    "    predictions_list = []\n",
    "    \n",
    "    # Initialize counters\n",
    "    total_images = 0\n",
    "    skipped_images = 0\n",
    "    \n",
    "    print(\"Starting zero-shot classification...\")\n",
    "    \n",
    "    for idx, row in tqdm(df_split.iterrows(), total=len(df_split), desc=\"Images\"):\n",
    "        img_id = row['img_id']\n",
    "        folder = row['folder']\n",
    "        img_path = os.path.join(folder, img_id + '.jpg')\n",
    "        \n",
    "        # Extract game_id and player_id from folder path\n",
    "        # Expected folder structure: .../player_crops/train/a-b/player_id/\n",
    "        folder_parts = folder.strip('/').split('/')\n",
    "        if len(folder_parts) < 3:\n",
    "            print(f\"Unexpected folder structure: {folder}. Skipping.\")\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "        \n",
    "        player_id_dir = folder_parts[-1]  # 'player_id'\n",
    "        game_play_dir = folder_parts[-2]  # 'a-b'\n",
    "        game_id_extracted = game_play_dir.split('-')[0]\n",
    "        \n",
    "        # Use extracted player_id and game_id\n",
    "        original_player_id = player_id_dir\n",
    "        game_id = game_id_extracted\n",
    "        \n",
    "        # Get player info from labels\n",
    "        player_info = labels.get(original_player_id)\n",
    "        if not player_info:\n",
    "            print(f\"Player ID '{original_player_id}' not found in labels. Skipping.\")\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "        \n",
    "        player_name_raw = player_info['player_name']\n",
    "        jersey_number_label = player_info['jersey_number']\n",
    "        player_name = clean_player_name(player_name_raw)\n",
    "        \n",
    "        # Get game info\n",
    "        game_info = game_player_attribute.get(game_id)\n",
    "        if not game_info:\n",
    "            print(f\"Game ID '{game_id}' not found in game_player_attribute. Skipping.\")\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "        \n",
    "        # Determine player's team in this game\n",
    "        teamA = game_info['teamA']\n",
    "        teamB = game_info['teamB']\n",
    "        colorA = game_info['colorA']\n",
    "        colorB = game_info['colorB']\n",
    "        \n",
    "        # Check if player is in teamA or teamB\n",
    "        player_team = None\n",
    "        jersey_color_gt = None\n",
    "        ethnicity_raw = 'unknown'\n",
    "        \n",
    "        # Search for player in game_info['players']\n",
    "        player_attributes = game_info['players'].get(player_name_raw)\n",
    "        if not player_attributes:\n",
    "            print(f\"Player '{player_name_raw}' not found in game '{game_id}'. Skipping.\")\n",
    "            skipped_images += 1\n",
    "            continue\n",
    "        \n",
    "        jersey_color_gt = player_attributes.get('jersey_color', 'unknown').lower()\n",
    "        jersey_number_gt = player_attributes.get('jersey_number', 'unknown').lower()\n",
    "        ethnicity_raw = player_attributes.get('ethnicity', 'unknown').lower()\n",
    "        \n",
    "        # Ground truth attributes\n",
    "        ground_truth_jersey_color = jersey_color_gt\n",
    "        ground_truth_jersey_number = jersey_number_gt\n",
    "        ground_truth_ethnicity = ethnicity_raw  # Assumed to be 'black' or 'white'\n",
    "        \n",
    "        total_images += 1\n",
    "        \n",
    "        # Perform zero-shot classification\n",
    "        predictions = zero_shot_classification(\n",
    "            img_path, clip_model, preprocess, device, class_embeddings\n",
    "        )\n",
    "        \n",
    "        # Append to the predictions list\n",
    "        predictions_list.append({\n",
    "            'image_path': img_path,\n",
    "            'player_id': original_player_id,\n",
    "            'player_name': player_name_raw,\n",
    "            'ground_truth_jersey_color': ground_truth_jersey_color,\n",
    "            'ground_truth_jersey_number': ground_truth_jersey_number,\n",
    "            'ground_truth_ethnicity': ground_truth_ethnicity,\n",
    "            'predicted_jersey_color_top1': predictions.get('jersey_color_top1', 'unknown'),\n",
    "            'predicted_jersey_color_top2': predictions.get('jersey_color_top2', ['unknown']),\n",
    "            'predicted_jersey_number_top1': predictions.get('jersey_number_top1', 'unknown'),\n",
    "            'predicted_jersey_number_top3': predictions.get('jersey_number_top3', ['unknown']),\n",
    "            'predicted_ethnicity': predictions.get('ethnicity', 'unknown')\n",
    "        })\n",
    "    \n",
    "    print(f\"\\nZero-shot classification completed.\")\n",
    "    print(f\"Total images processed: {total_images}\")\n",
    "    print(f\"Total images skipped: {skipped_images}\")\n",
    "    \n",
    "    # Convert the list of predictions to a DataFrame\n",
    "    predictions_df = pd.DataFrame(predictions_list)\n",
    "    \n",
    "    # Normalize labels for consistency\n",
    "    for attr in ['ground_truth_ethnicity', 'predicted_ethnicity']:\n",
    "        predictions_df[attr] = predictions_df[attr].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    # ------------------------ Evaluation ------------------------\n",
    "    \n",
    "    # Debugging: Inspect a sample of ground truth and predictions\n",
    "    # print(\"\\nSample of Ground Truth vs Predicted Ethnicity:\")\n",
    "    # print(predictions_df[['ground_truth_ethnicity', 'predicted_ethnicity']].head(20))\n",
    "    \n",
    "    # print(\"\\nUnique Ground Truth Ethnicities:\", predictions_df['ground_truth_ethnicity'].unique())\n",
    "    # print(\"Unique Predicted Ethnicities:\", predictions_df['predicted_ethnicity'].unique())\n",
    "    \n",
    "    # Evaluate predictions\n",
    "    print(\"\\nEvaluating predictions...\")\n",
    "    metrics = evaluate_predictions(predictions_df)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nZero-Shot Classification Metrics:\")\n",
    "    for attr, metric in metrics.items():\n",
    "        print(f\"\\nAttribute: {attr}\")\n",
    "        if metric:\n",
    "            print(f\" - Top-1 Accuracy: {metric['top1_accuracy']:.4f}\")\n",
    "            if f\"top{2}_accuracy\" in metric:\n",
    "                print(f\" - Top-2 Accuracy: {metric[f'top2_accuracy']:.4f}\")\n",
    "            if f\"top{3}_accuracy\" in metric:\n",
    "                print(f\" - Top-3 Accuracy: {metric[f'top3_accuracy']:.4f}\")\n",
    "            print(f\" - Precision: {metric['top1_precision']:.4f}\")\n",
    "            print(f\" - Recall: {metric['top1_recall']:.4f}\")\n",
    "            print(f\" - F1 Score: {metric['top1_f1_score']:.4f}\")\n",
    "        else:\n",
    "            print(\" - No valid predictions to evaluate.\")\n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    output_predictions_csv = os.path.join(output_folder, f'ZS_predictions_full_{split}.csv')\n",
    "    predictions_df.to_csv(output_predictions_csv, index=False)\n",
    "    print(f\"\\nPredictions have been saved to '{output_predictions_csv}'\")\n",
    "    \n",
    "    # Close log file and restore stdout\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = original_stdout\n",
    "    print(f\"Log file has been saved to '{log_file_path}'\")\n",
    "\n",
    "# ------------------------ Main Function ------------------------\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to execute zero-shot attribute classification.\n",
    "    \"\"\"\n",
    "    # Define parameters\n",
    "    \n",
    "    # Paths to necessary files\n",
    "    labels_file = '/home/minxing/datasets/NSVA_157_zero_shot_minxing/ZeroShotDataset_labels.txt'\n",
    "    player_summaries_file = '/home/minxing/code/NSVA_MOTR/tools/player_summaries_final.json'\n",
    "    game_player_attribute_path = \"/home/minxing/code/clip_reident/output_embeds/game_player_attribute.json\"\n",
    "    embedding_info_path = \"/home/minxing/code/clip_reident/output_embeds/embedding_info.json\"\n",
    "    \n",
    "    # Data CSV path\n",
    "    data_csv_path = config.data_csv  # Path to your train_df.csv\n",
    "    \n",
    "    output_folder = config.output_folder  # Directory to save outputs\n",
    "    \n",
    "    # Parameters for the classification task\n",
    "    split = config.split  # 'train' or 'test'\n",
    "    \n",
    "    # Ensure output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Execute the classification task\n",
    "    classification_task(\n",
    "        labels_file=labels_file,\n",
    "        player_summaries_file=player_summaries_file,\n",
    "        game_player_attribute_path=game_player_attribute_path,\n",
    "        embedding_info_path=embedding_info_path,\n",
    "        data_csv_path=data_csv_path,\n",
    "        output_folder=output_folder,\n",
    "        split=split\n",
    "    )\n",
    "\n",
    "# ------------------------ Execute the Main Function ------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipreident",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
